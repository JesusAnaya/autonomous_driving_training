{
 "cells": [
  {
   "cell_type": "code",
   "id": "016b93d2-c0ae-4f9c-bfd6-4bf302a27c0c",
   "metadata": {
    "executionInfo": {
     "elapsed": 222,
     "status": "ok",
     "timestamp": 1712390910851,
     "user": {
      "displayName": "Jesus Armando Anaya",
      "userId": "10837992074590593370"
     },
     "user_tz": 420
    },
    "id": "016b93d2-c0ae-4f9c-bfd6-4bf302a27c0c",
    "ExecuteTime": {
     "end_time": "2024-04-19T07:15:03.720883Z",
     "start_time": "2024-04-19T07:15:03.718412Z"
    }
   },
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "8a0a6718-a28b-42ca-9656-884c3a31460a",
   "metadata": {
    "executionInfo": {
     "elapsed": 3389,
     "status": "ok",
     "timestamp": 1712390914449,
     "user": {
      "displayName": "Jesus Armando Anaya",
      "userId": "10837992074590593370"
     },
     "user_tz": 420
    },
    "id": "8a0a6718-a28b-42ca-9656-884c3a31460a",
    "ExecuteTime": {
     "end_time": "2024-04-19T07:15:03.765819Z",
     "start_time": "2024-04-19T07:15:03.741008Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import IPython.display as display\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import zipfile\n",
    "from PIL import Image, ImageDraw\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import KFold\n",
    "import random"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "b1dcc786-7988-493e-ac97-4aff35cddd08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T07:15:03.802995Z",
     "start_time": "2024-04-19T07:15:03.766708Z"
    }
   },
   "source": [
    "is_colab = False"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "fed89e8b6aeb01dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T07:15:03.848418Z",
     "start_time": "2024-04-19T07:15:03.804020Z"
    }
   },
   "source": [
    "tf.random.set_seed(0)\n",
    "random.seed(0)\n"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "7f23393c-24d3-4bc4-a0db-f18b200765a5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1712390914837,
     "user": {
      "displayName": "Jesus Armando Anaya",
      "userId": "10837992074590593370"
     },
     "user_tz": 420
    },
    "id": "7f23393c-24d3-4bc4-a0db-f18b200765a5",
    "outputId": "2cddf7e4-7d94-4da9-df2a-b6e7bfb35c59",
    "ExecuteTime": {
     "end_time": "2024-04-19T07:15:03.889339Z",
     "start_time": "2024-04-19T07:15:03.849993Z"
    }
   },
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"TensorFlow version: \", tf.__version__)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "TensorFlow version:  2.15.0\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "91112d1d-bc33-494c-abe6-be815995e836",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1712390914837,
     "user": {
      "displayName": "Jesus Armando Anaya",
      "userId": "10837992074590593370"
     },
     "user_tz": 420
    },
    "id": "91112d1d-bc33-494c-abe6-be815995e836",
    "ExecuteTime": {
     "end_time": "2024-04-19T07:15:03.919705Z",
     "start_time": "2024-04-19T07:15:03.892426Z"
    }
   },
   "source": [
    "def parse_tfrecord_fn(example_proto):\n",
    "    # Define the feature description for parsing\n",
    "    feature_description = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'steering': tf.io.FixedLenFeature([], tf.float32),\n",
    "    }\n",
    "\n",
    "    parsed_features = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    image = tf.image.decode_jpeg(parsed_features['image'], channels=3)\n",
    "    steering = parsed_features['steering']\n",
    "    \n",
    "    # Add random brightness change as data augmentation\n",
    "    # if random.random() > 0.5:\n",
    "    #     image = tf.image.random_brightness(image, 0.5)\n",
    "    # \n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = image / 255.0\n",
    "\n",
    "    return image, steering\n"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "4a83ec71-287b-43e9-ba84-9c0aa19957fe",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1712390914837,
     "user": {
      "displayName": "Jesus Armando Anaya",
      "userId": "10837992074590593370"
     },
     "user_tz": 420
    },
    "id": "4a83ec71-287b-43e9-ba84-9c0aa19957fe",
    "ExecuteTime": {
     "end_time": "2024-04-19T07:15:03.957841Z",
     "start_time": "2024-04-19T07:15:03.920551Z"
    }
   },
   "source": [
    "def load_dataset(tfrecord_files):\n",
    "    raw_dataset = tf.data.TFRecordDataset(tfrecord_files)\n",
    "    return raw_dataset.map(parse_tfrecord_fn)"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "et51X-H4cfbz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22112,
     "status": "ok",
     "timestamp": 1712390937832,
     "user": {
      "displayName": "Jesus Armando Anaya",
      "userId": "10837992074590593370"
     },
     "user_tz": 420
    },
    "id": "et51X-H4cfbz",
    "outputId": "efbadb09-3d11-4a1d-e28c-a2d9354a3bdb",
    "ExecuteTime": {
     "end_time": "2024-04-19T07:15:03.995838Z",
     "start_time": "2024-04-19T07:15:03.958815Z"
    }
   },
   "source": [
    "if is_colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    if not os.path.exists(\"datasets\"):\n",
    "        os.makedirs(\"datasets\")\n",
    "    \n",
    "    path_to_zip_file = \"/content/drive/MyDrive/Colab Notebooks/AD/datasets/dataset_2024-04-0.zip\"\n",
    "    with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(\"./datasets\")\n",
    "\n",
    "    tfrecord_files = list(glob.glob(\"./datasets/*.tfrecord\"))\n",
    "else:\n",
    "    tfrecord_files = list(glob.glob(\"/home/anaya/Develop/autonomous_driving_training/datasets/*.tfrecord\"))"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "id": "569ed786e2a3ea99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T07:15:04.034925Z",
     "start_time": "2024-04-19T07:15:03.997017Z"
    }
   },
   "source": [
    "def get_model():\n",
    "    return tf.keras.Sequential([\n",
    "        # First convolutional layer, input shape specified\n",
    "        layers.InputLayer((66, 200, 3)),\n",
    "        layers.Conv2D(24, kernel_size=5, strides=2),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.ReLU(),\n",
    "    \n",
    "        # Second convolutional layer\n",
    "        layers.Conv2D(36, kernel_size=5, strides=2),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.ReLU(),\n",
    "    \n",
    "        # Third convolutional layer\n",
    "        layers.Conv2D(48, kernel_size=5, strides=2),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.ReLU(),\n",
    "    \n",
    "        # Fourth convolutional layer\n",
    "        layers.Conv2D(64, kernel_size=3, strides=1),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.ReLU(),\n",
    "    \n",
    "        # Fifth convolutional layer\n",
    "        layers.Conv2D(64, kernel_size=3, strides=1),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.ReLU(),\n",
    "    \n",
    "        # Flatten the output to feed into the dense layers\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "    \n",
    "        # First fully connected layer\n",
    "        layers.Dense(1164),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.ReLU(),\n",
    "    \n",
    "        # Second fully connected layer\n",
    "        layers.Dense(100),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.ReLU(),\n",
    "    \n",
    "        # Third fully connected layer\n",
    "        layers.Dense(50),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.ReLU(),\n",
    "    \n",
    "        # Fourth fully connected layer\n",
    "        layers.Dense(10),\n",
    "        layers.ReLU(),\n",
    "    \n",
    "        # Output layer\n",
    "        layers.Dense(1)\n",
    "    ])"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "id": "0cb9d87c-a872-4e94-87e4-140025763167",
   "metadata": {
    "executionInfo": {
     "elapsed": 73729,
     "status": "ok",
     "timestamp": 1712391025239,
     "user": {
      "displayName": "Jesus Armando Anaya",
      "userId": "10837992074590593370"
     },
     "user_tz": 420
    },
    "id": "0cb9d87c-a872-4e94-87e4-140025763167",
    "ExecuteTime": {
     "end_time": "2024-04-19T07:15:07.746111Z",
     "start_time": "2024-04-19T07:15:04.037372Z"
    }
   },
   "source": [
    "\n",
    "parsed_dataset = load_dataset(tfrecord_files)\n",
    "shuffled_dataset = parsed_dataset.shuffle(2040)\n",
    "\n",
    "# Determine split sizes\n",
    "total_items = sum([1 for _ in shuffled_dataset.as_numpy_iterator()])\n",
    "\n",
    "num_folds = 4\n",
    "fold_size = total_items // num_folds"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "id": "3494288b50d41039",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1712391025239,
     "user": {
      "displayName": "Jesus Armando Anaya",
      "userId": "10837992074590593370"
     },
     "user_tz": 420
    },
    "id": "3494288b50d41039",
    "outputId": "917c543f-c444-4898-b482-c3e69b0e881d",
    "ExecuteTime": {
     "end_time": "2024-04-19T07:15:07.749358Z",
     "start_time": "2024-04-19T07:15:07.747082Z"
    }
   },
   "source": [
    "print(\"Total items: \", total_items)\n",
    "print(\"Fold size: \", fold_size)\n",
    "print(\"Number of folds: \", num_folds)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total items:  49701\n",
      "Fold size:  12425\n",
      "Number of folds:  4\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "id": "1ac24967b8507931",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T07:15:07.797569Z",
     "start_time": "2024-04-19T07:15:07.750103Z"
    }
   },
   "source": [
    "# NOTE - Restart experiment from here\n",
    "tf.random.set_seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "# Create an array of datasets for each fold\n",
    "datasets_for_fold = []\n",
    "\n",
    "for i in range(num_folds):\n",
    "    start = i * fold_size\n",
    "    datasets_for_fold.append(shuffled_dataset.skip(start).take(fold_size))\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "id": "80ec2e72993dc7fb",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1712396065932,
     "user": {
      "displayName": "Jesus Armando Anaya",
      "userId": "10837992074590593370"
     },
     "user_tz": 420
    },
    "id": "80ec2e72993dc7fb",
    "ExecuteTime": {
     "end_time": "2024-04-19T07:15:07.847690Z",
     "start_time": "2024-04-19T07:15:07.798929Z"
    }
   },
   "source": [
    "log_dir = \"./logs/cv/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# Only add the loss to the tensorboard callback\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, write_images=True, update_freq='epoch', profile_batch=2, embeddings_freq=1)"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T07:15:07.862643Z",
     "start_time": "2024-04-19T07:15:07.848544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "experiments = {\n",
    "    # \"experiment_4\": {\n",
    "    #     \"learning_rate\": 1e-4,\n",
    "    #     \"weight_decay\": 1e-5,\n",
    "    #     \"scheduler\": \"constant\",\n",
    "    # },\n",
    "    # \"experiment_3\": {\n",
    "    #     \"learning_rate\": 1e-4,\n",
    "    #     \"weight_decay\": 1e-6,\n",
    "    #     \"scheduler\": \"constant\",\n",
    "    # },\n",
    "    \"experiment_5\": {\n",
    "        \"learning_rate\": 1e-5,\n",
    "        \"weight_decay\": 1e-5,\n",
    "        \"scheduler\": \"constant\",\n",
    "    },\n",
    "    \"experiment_6\": {\n",
    "        \"learning_rate\": 1e-5,\n",
    "        \"weight_decay\": 1e-6,\n",
    "        \"scheduler\": \"constant\",\n",
    "    },\n",
    "    \"experiment_7\": {\n",
    "        \"learning_rate\": 1e-5,\n",
    "        \"weight_decay\": 1e-7,\n",
    "        \"scheduler\": \"constant\",\n",
    "    },\n",
    "    \"experiment_8\": {\n",
    "        \"learning_rate\": 1e-6,\n",
    "        \"weight_decay\": 1e-6,\n",
    "        \"scheduler\": \"constant\",\n",
    "    },\n",
    "    \"experiment_9\": {\n",
    "        \"learning_rate\": 1e-5,\n",
    "        \"weight_decay\": 1e-5,\n",
    "        \"scheduler\": \"step\",\n",
    "    },\n",
    "    \"experiment_10\": {\n",
    "        \"learning_rate\": 1e-5,\n",
    "        \"weight_decay\": 1e-6,\n",
    "        \"scheduler\": \"step\",\n",
    "    },\n",
    "}"
   ],
   "id": "4719ebd03d57e484",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T07:15:07.900353Z",
     "start_time": "2024-04-19T07:15:07.863667Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def meta_scheduler(steps, alpha=0.1):\n",
    "    def scheduler(epoch, lr):\n",
    "        if isinstance(steps, int):\n",
    "            if epoch % (steps - 1) == 0 and epoch != 0:\n",
    "                return lr * alpha\n",
    "            else:\n",
    "                return lr\n",
    "        elif isinstance(steps, list):\n",
    "            if epoch in steps:\n",
    "                return lr * alpha\n",
    "            else:\n",
    "                return lr\n",
    "        else:\n",
    "            raise ValueError(\"Invalid steps parameter\")\n",
    "    return scheduler"
   ],
   "id": "5b416a086a1fb05",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T07:15:07.941183Z",
     "start_time": "2024-04-19T07:15:07.900988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def steering_accuracy(threshold=0.05):\n",
    "    def SA(y_true, y_pred):\n",
    "        return K.mean(K.cast(K.less_equal(K.abs(y_true - y_pred), threshold), K.floatx()))\n",
    "    return SA"
   ],
   "id": "2f27b742a14116a7",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T07:15:07.980857Z",
     "start_time": "2024-04-19T07:15:07.942590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Use experimental.sample_from_datasets to approximate K-Fold\n",
    "\n",
    "def run_cross_validation(experiment_name: str, experiment_params: dict, batch_size: int = 64):\n",
    "    for i in range(num_folds):\n",
    "        tf.random.set_seed(0)\n",
    "        random.seed(0)\n",
    "    \n",
    "        train_datasets = [ds for j, ds in enumerate(datasets_for_fold) if j != i]\n",
    "         # Concatenate the datasets\n",
    "        train_dataset = train_datasets[0]\n",
    "        for ds in train_datasets[1:]:\n",
    "            train_dataset = train_dataset.concatenate(ds)\n",
    "        \n",
    "        # Validation dataset\n",
    "        val_dataset = datasets_for_fold[i]\n",
    "        \n",
    "        model = get_model()\n",
    "        \n",
    "        # Compile the model (make sure to specify the loss and optimizer)\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(\n",
    "                learning_rate=experiment_params[\"learning_rate\"],\n",
    "                weight_decay=experiment_params[\"weight_decay\"]\n",
    "            ),\n",
    "            loss=tf.keras.losses.MeanSquaredError(),\n",
    "            metrics=[steering_accuracy()]\n",
    "        )\n",
    "        \n",
    "        train_early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=4, min_delta=0.0005)\n",
    "        val_early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4, min_delta=0.0005)\n",
    "        callbacks_list = [tensorboard_callback, train_early_stopping, val_early_stopping]\n",
    "        \n",
    "        # Adding scheduler\n",
    "        if experiment_params[\"scheduler\"] == \"step\":\n",
    "            callback_lr_scheduler = tf.keras.callbacks.LearningRateScheduler(meta_scheduler(15, 0.1))\n",
    "            callbacks_list.append(callback_lr_scheduler)\n",
    "    \n",
    "        # Fit the model, add fold number as suffix to the log directory\n",
    "        print(f\"Cross-validation: {experiment_name} on fold {i + 1}\")\n",
    "        print(\"Params: \", experiment_params)\n",
    "        tensorboard_callback.log_dir = log_dir + f\"/{experiment_name}/fold_{i + 1}\"\n",
    "\n",
    "        model.fit(\n",
    "            train_dataset.batch(batch_size, drop_remainder=True).prefetch(tf.data.AUTOTUNE),\n",
    "            validation_data=val_dataset.batch(batch_size, drop_remainder=True).prefetch(tf.data.AUTOTUNE),\n",
    "            callbacks=callbacks_list,\n",
    "            epochs=30\n",
    "        )\n",
    "       \n"
   ],
   "id": "a13db56a65d1ebb3",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T08:14:14.646451Z",
     "start_time": "2024-04-19T07:15:07.982503Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for experiment_name, experiment_params in experiments.items():\n",
    "    run_cross_validation(experiment_name, experiment_params, batch_size=40)\n"
   ],
   "id": "d1742daeb26d511a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation: experiment_5 on fold 1\n",
      "Epoch 1/30\n",
      "931/931 [==============================] - 13s 11ms/step - loss: 0.5724 - SA: 0.0601 - val_loss: 0.2781 - val_SA: 0.0736\n",
      "Epoch 2/30\n",
      "931/931 [==============================] - 9s 10ms/step - loss: 0.2979 - SA: 0.0800 - val_loss: 0.1924 - val_SA: 0.0939\n",
      "Epoch 3/30\n",
      "931/931 [==============================] - 9s 10ms/step - loss: 0.1797 - SA: 0.1006 - val_loss: 0.1230 - val_SA: 0.1271\n",
      "Epoch 4/30\n",
      "931/931 [==============================] - 10s 11ms/step - loss: 0.1158 - SA: 0.1277 - val_loss: 0.0906 - val_SA: 0.1596\n",
      "Epoch 5/30\n",
      "931/931 [==============================] - 10s 11ms/step - loss: 0.0827 - SA: 0.1538 - val_loss: 0.0744 - val_SA: 0.1869\n",
      "Epoch 6/30\n",
      "931/931 [==============================] - 10s 10ms/step - loss: 0.0629 - SA: 0.1810 - val_loss: 0.0690 - val_SA: 0.2018\n",
      "Epoch 7/30\n",
      "931/931 [==============================] - 9s 10ms/step - loss: 0.0515 - SA: 0.2053 - val_loss: 0.0644 - val_SA: 0.2315\n",
      "Epoch 8/30\n",
      "931/931 [==============================] - 10s 10ms/step - loss: 0.0428 - SA: 0.2345 - val_loss: 0.0615 - val_SA: 0.2422\n",
      "Epoch 9/30\n",
      "931/931 [==============================] - 10s 10ms/step - loss: 0.0378 - SA: 0.2582 - val_loss: 0.0612 - val_SA: 0.2458\n",
      "Epoch 10/30\n",
      "931/931 [==============================] - 9s 10ms/step - loss: 0.0337 - SA: 0.2852 - val_loss: 0.0583 - val_SA: 0.2631\n",
      "Epoch 11/30\n",
      "931/931 [==============================] - 9s 10ms/step - loss: 0.0303 - SA: 0.3115 - val_loss: 0.0574 - val_SA: 0.2764\n",
      "Epoch 12/30\n",
      "931/931 [==============================] - 10s 10ms/step - loss: 0.0272 - SA: 0.3281 - val_loss: 0.0564 - val_SA: 0.2674\n",
      "Epoch 13/30\n",
      "931/931 [==============================] - 9s 10ms/step - loss: 0.0250 - SA: 0.3406 - val_loss: 0.0540 - val_SA: 0.2814\n",
      "Epoch 14/30\n",
      "931/931 [==============================] - 9s 9ms/step - loss: 0.0230 - SA: 0.3546 - val_loss: 0.0520 - val_SA: 0.2836\n",
      "Epoch 15/30\n",
      "931/931 [==============================] - 9s 10ms/step - loss: 0.0212 - SA: 0.3713 - val_loss: 0.0503 - val_SA: 0.3018\n",
      "Epoch 16/30\n",
      "931/931 [==============================] - 9s 10ms/step - loss: 0.0195 - SA: 0.3829 - val_loss: 0.0481 - val_SA: 0.3315\n",
      "Epoch 17/30\n",
      "931/931 [==============================] - 9s 9ms/step - loss: 0.0184 - SA: 0.3951 - val_loss: 0.0477 - val_SA: 0.3332\n",
      "Epoch 18/30\n",
      "931/931 [==============================] - 9s 9ms/step - loss: 0.0171 - SA: 0.4136 - val_loss: 0.0476 - val_SA: 0.3519\n",
      "Epoch 19/30\n",
      "931/931 [==============================] - 9s 10ms/step - loss: 0.0162 - SA: 0.4158 - val_loss: 0.0450 - val_SA: 0.3819\n",
      "Epoch 20/30\n",
      "931/931 [==============================] - 9s 9ms/step - loss: 0.0152 - SA: 0.4281 - val_loss: 0.0443 - val_SA: 0.3806\n",
      "Epoch 21/30\n",
      "931/931 [==============================] - 9s 10ms/step - loss: 0.0144 - SA: 0.4358 - val_loss: 0.0442 - val_SA: 0.3866\n",
      "Epoch 22/30\n",
      "931/931 [==============================] - 8s 9ms/step - loss: 0.0140 - SA: 0.4447 - val_loss: 0.0409 - val_SA: 0.4002\n",
      "Epoch 23/30\n",
      "931/931 [==============================] - 8s 9ms/step - loss: 0.0131 - SA: 0.4563 - val_loss: 0.0415 - val_SA: 0.3983\n",
      "Epoch 24/30\n",
      "931/931 [==============================] - 8s 9ms/step - loss: 0.0125 - SA: 0.4647 - val_loss: 0.0404 - val_SA: 0.4118\n",
      "Epoch 25/30\n",
      "931/931 [==============================] - 10s 11ms/step - loss: 0.0120 - SA: 0.4689 - val_loss: 0.0391 - val_SA: 0.4185\n",
      "Epoch 26/30\n",
      "931/931 [==============================] - 11s 11ms/step - loss: 0.0113 - SA: 0.4825 - val_loss: 0.0400 - val_SA: 0.4153\n",
      "Epoch 27/30\n",
      "931/931 [==============================] - 10s 11ms/step - loss: 0.0109 - SA: 0.4865 - val_loss: 0.0384 - val_SA: 0.4239\n",
      "Epoch 28/30\n",
      "931/931 [==============================] - 10s 11ms/step - loss: 0.0107 - SA: 0.4949 - val_loss: 0.0366 - val_SA: 0.4152\n",
      "Epoch 29/30\n",
      "931/931 [==============================] - 11s 12ms/step - loss: 0.0103 - SA: 0.4984 - val_loss: 0.0360 - val_SA: 0.4291\n",
      "Epoch 30/30\n",
      "931/931 [==============================] - 11s 11ms/step - loss: 0.0099 - SA: 0.5056 - val_loss: 0.0361 - val_SA: 0.4319\n",
      "Cross-validation: experiment_5 on fold 2\n",
      "Epoch 1/30\n",
      "931/931 [==============================] - 12s 10ms/step - loss: 0.5852 - SA: 0.0573 - val_loss: 0.3563 - val_SA: 0.0590\n",
      "Epoch 2/30\n",
      "931/931 [==============================] - 9s 10ms/step - loss: 0.3198 - SA: 0.0767 - val_loss: 0.3597 - val_SA: 0.0608\n",
      "Epoch 3/30\n",
      "931/931 [==============================] - 9s 10ms/step - loss: 0.2026 - SA: 0.0966 - val_loss: 0.2829 - val_SA: 0.0787\n",
      "Epoch 4/30\n",
      "931/931 [==============================] - 10s 11ms/step - loss: 0.1408 - SA: 0.1144 - val_loss: 0.1915 - val_SA: 0.1012\n",
      "Epoch 5/30\n",
      "931/931 [==============================] - 10s 10ms/step - loss: 0.1025 - SA: 0.1352 - val_loss: 0.1263 - val_SA: 0.1167\n",
      "Epoch 6/30\n",
      "931/931 [==============================] - 10s 11ms/step - loss: 0.0784 - SA: 0.1557 - val_loss: 0.0789 - val_SA: 0.1474\n",
      "Epoch 7/30\n",
      "931/931 [==============================] - 9s 10ms/step - loss: 0.0619 - SA: 0.1855 - val_loss: 0.0669 - val_SA: 0.1602\n",
      "Epoch 8/30\n",
      "931/931 [==============================] - 9s 10ms/step - loss: 0.0512 - SA: 0.2107 - val_loss: 0.0569 - val_SA: 0.1766\n",
      "Epoch 9/30\n",
      "931/931 [==============================] - 9s 9ms/step - loss: 0.0443 - SA: 0.2315 - val_loss: 0.0543 - val_SA: 0.1940\n",
      "Epoch 10/30\n",
      "931/931 [==============================] - 9s 9ms/step - loss: 0.0389 - SA: 0.2547 - val_loss: 0.0504 - val_SA: 0.2277\n",
      "Epoch 11/30\n",
      "931/931 [==============================] - 9s 9ms/step - loss: 0.0349 - SA: 0.2803 - val_loss: 0.0487 - val_SA: 0.2410\n",
      "Epoch 12/30\n",
      "931/931 [==============================] - 9s 9ms/step - loss: 0.0312 - SA: 0.2960 - val_loss: 0.0463 - val_SA: 0.2675\n",
      "Epoch 13/30\n",
      "931/931 [==============================] - 9s 10ms/step - loss: 0.0282 - SA: 0.3121 - val_loss: 0.0453 - val_SA: 0.2918\n",
      "Epoch 14/30\n",
      "931/931 [==============================] - 9s 9ms/step - loss: 0.0259 - SA: 0.3280 - val_loss: 0.0438 - val_SA: 0.3069\n",
      "Epoch 15/30\n",
      "931/931 [==============================] - 8s 9ms/step - loss: 0.0239 - SA: 0.3426 - val_loss: 0.0426 - val_SA: 0.3193\n",
      "Epoch 16/30\n",
      "931/931 [==============================] - 9s 10ms/step - loss: 0.0220 - SA: 0.3550 - val_loss: 0.0401 - val_SA: 0.3371\n",
      "Epoch 17/30\n",
      "931/931 [==============================] - 8s 9ms/step - loss: 0.0205 - SA: 0.3698 - val_loss: 0.0403 - val_SA: 0.3133\n",
      "Epoch 18/30\n",
      "931/931 [==============================] - 9s 9ms/step - loss: 0.0194 - SA: 0.3830 - val_loss: 0.0382 - val_SA: 0.3523\n",
      "Epoch 19/30\n",
      "931/931 [==============================] - 9s 9ms/step - loss: 0.0180 - SA: 0.3970 - val_loss: 0.0371 - val_SA: 0.3786\n",
      "Epoch 20/30\n",
      "931/931 [==============================] - 8s 9ms/step - loss: 0.0170 - SA: 0.4031 - val_loss: 0.0375 - val_SA: 0.3582\n",
      "Epoch 21/30\n",
      "931/931 [==============================] - 9s 9ms/step - loss: 0.0165 - SA: 0.4144 - val_loss: 0.0346 - val_SA: 0.3748\n",
      "Epoch 22/30\n",
      "931/931 [==============================] - 9s 10ms/step - loss: 0.0153 - SA: 0.4231 - val_loss: 0.0331 - val_SA: 0.4041\n",
      "Epoch 23/30\n",
      "931/931 [==============================] - 8s 9ms/step - loss: 0.0147 - SA: 0.4349 - val_loss: 0.0327 - val_SA: 0.4115\n",
      "Epoch 24/30\n",
      "931/931 [==============================] - 9s 9ms/step - loss: 0.0141 - SA: 0.4461 - val_loss: 0.0308 - val_SA: 0.4195\n",
      "Epoch 25/30\n",
      "931/931 [==============================] - 9s 9ms/step - loss: 0.0134 - SA: 0.4569 - val_loss: 0.0309 - val_SA: 0.4018\n",
      "Epoch 26/30\n",
      "931/931 [==============================] - 9s 9ms/step - loss: 0.0125 - SA: 0.4672 - val_loss: 0.0298 - val_SA: 0.4272\n",
      "Epoch 27/30\n",
      "931/931 [==============================] - 8s 9ms/step - loss: 0.0123 - SA: 0.4746 - val_loss: 0.0291 - val_SA: 0.4220\n",
      "Epoch 28/30\n",
      "931/931 [==============================] - 9s 9ms/step - loss: 0.0119 - SA: 0.4789 - val_loss: 0.0285 - val_SA: 0.4387\n",
      "Epoch 29/30\n",
      "931/931 [==============================] - 8s 9ms/step - loss: 0.0115 - SA: 0.4939 - val_loss: 0.0284 - val_SA: 0.4375\n",
      "Epoch 30/30\n",
      "931/931 [==============================] - 9s 9ms/step - loss: 0.0109 - SA: 0.4947 - val_loss: 0.0267 - val_SA: 0.4435\n",
      "Cross-validation: experiment_5 on fold 3\n",
      "Epoch 1/30\n",
      "931/931 [==============================] - 11s 10ms/step - loss: 0.5749 - SA: 0.0585 - val_loss: 0.3278 - val_SA: 0.0516\n",
      "Epoch 2/30\n",
      "931/931 [==============================] - 9s 10ms/step - loss: 0.3006 - SA: 0.0764 - val_loss: 0.2495 - val_SA: 0.0593\n",
      "Epoch 3/30\n",
      "931/931 [==============================] - 9s 10ms/step - loss: 0.1845 - SA: 0.0959 - val_loss: 0.1735 - val_SA: 0.0677\n",
      "Epoch 4/30\n",
      "931/931 [==============================] - 9s 10ms/step - loss: 0.1254 - SA: 0.1197 - val_loss: 0.1028 - val_SA: 0.1015\n",
      "Epoch 5/30\n",
      "931/931 [==============================] - 9s 10ms/step - loss: 0.0913 - SA: 0.1437 - val_loss: 0.0690 - val_SA: 0.1357\n",
      "Epoch 6/30\n",
      "931/931 [==============================] - 9s 10ms/step - loss: 0.0704 - SA: 0.1680 - val_loss: 0.0485 - val_SA: 0.1915\n",
      "Epoch 7/30\n",
      "931/931 [==============================] - 9s 10ms/step - loss: 0.0577 - SA: 0.1951 - val_loss: 0.0422 - val_SA: 0.2397\n",
      "Epoch 8/30\n",
      "931/931 [==============================] - 9s 10ms/step - loss: 0.0492 - SA: 0.2136 - val_loss: 0.0391 - val_SA: 0.2569\n",
      "Epoch 9/30\n",
      "931/931 [==============================] - 9s 9ms/step - loss: 0.0419 - SA: 0.2396 - val_loss: 0.0378 - val_SA: 0.2726\n",
      "Epoch 10/30\n",
      "931/931 [==============================] - 9s 10ms/step - loss: 0.0370 - SA: 0.2646 - val_loss: 0.0372 - val_SA: 0.2720\n",
      "Epoch 11/30\n",
      "931/931 [==============================] - 9s 10ms/step - loss: 0.0333 - SA: 0.2880 - val_loss: 0.0372 - val_SA: 0.2576\n",
      "Epoch 12/30\n",
      "931/931 [==============================] - 9s 10ms/step - loss: 0.0306 - SA: 0.2998 - val_loss: 0.0363 - val_SA: 0.2588\n",
      "Epoch 13/30\n",
      "931/931 [==============================] - 9s 9ms/step - loss: 0.0283 - SA: 0.3279 - val_loss: 0.0385 - val_SA: 0.2082\n",
      "Epoch 14/30\n",
      "931/931 [==============================] - 9s 10ms/step - loss: 0.0260 - SA: 0.3318 - val_loss: 0.0354 - val_SA: 0.2160\n",
      "Epoch 15/30\n",
      "931/931 [==============================] - 9s 9ms/step - loss: 0.0247 - SA: 0.3426 - val_loss: 0.0350 - val_SA: 0.2064\n",
      "Epoch 16/30\n",
      "931/931 [==============================] - 9s 9ms/step - loss: 0.0228 - SA: 0.3568 - val_loss: 0.0339 - val_SA: 0.2215\n",
      "Epoch 17/30\n",
      "931/931 [==============================] - 9s 9ms/step - loss: 0.0211 - SA: 0.3690 - val_loss: 0.0328 - val_SA: 0.2471\n",
      "Epoch 18/30\n",
      "931/931 [==============================] - 9s 10ms/step - loss: 0.0200 - SA: 0.3822 - val_loss: 0.0309 - val_SA: 0.2788\n",
      "Epoch 19/30\n",
      "931/931 [==============================] - 9s 10ms/step - loss: 0.0188 - SA: 0.3908 - val_loss: 0.0303 - val_SA: 0.3194\n",
      "Epoch 20/30\n",
      "931/931 [==============================] - 9s 10ms/step - loss: 0.0176 - SA: 0.3937 - val_loss: 0.0282 - val_SA: 0.3654\n",
      "Epoch 21/30\n",
      "931/931 [==============================] - 9s 10ms/step - loss: 0.0169 - SA: 0.4090 - val_loss: 0.0279 - val_SA: 0.3516\n",
      "Epoch 22/30\n",
      "931/931 [==============================] - 9s 9ms/step - loss: 0.0156 - SA: 0.4127 - val_loss: 0.0276 - val_SA: 0.3521\n",
      "Epoch 23/30\n",
      "931/931 [==============================] - 9s 9ms/step - loss: 0.0152 - SA: 0.4243 - val_loss: 0.0261 - val_SA: 0.3802\n",
      "Epoch 24/30\n",
      "931/931 [==============================] - 9s 10ms/step - loss: 0.0142 - SA: 0.4295 - val_loss: 0.0243 - val_SA: 0.3998\n",
      "Epoch 25/30\n",
      "931/931 [==============================] - 9s 9ms/step - loss: 0.0137 - SA: 0.4396 - val_loss: 0.0247 - val_SA: 0.3808\n",
      "Epoch 26/30\n",
      "931/931 [==============================] - 9s 10ms/step - loss: 0.0133 - SA: 0.4473 - val_loss: 0.0231 - val_SA: 0.4267\n",
      "Epoch 27/30\n",
      "931/931 [==============================] - 9s 9ms/step - loss: 0.0126 - SA: 0.4546 - val_loss: 0.0224 - val_SA: 0.4311\n",
      "Epoch 28/30\n",
      "931/931 [==============================] - 8s 9ms/step - loss: 0.0122 - SA: 0.4600 - val_loss: 0.0218 - val_SA: 0.4596\n",
      "Epoch 29/30\n",
      "931/931 [==============================] - 8s 9ms/step - loss: 0.0118 - SA: 0.4644 - val_loss: 0.0225 - val_SA: 0.4447\n",
      "Epoch 30/30\n",
      "931/931 [==============================] - 9s 9ms/step - loss: 0.0114 - SA: 0.4700 - val_loss: 0.0209 - val_SA: 0.4407\n",
      "Cross-validation: experiment_5 on fold 4\n",
      "Epoch 1/30\n",
      "931/931 [==============================] - 10s 8ms/step - loss: 0.5881 - SA: 0.0560 - val_loss: 0.6863 - val_SA: 0.0672\n",
      "Epoch 2/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.3081 - SA: 0.0779 - val_loss: 0.4516 - val_SA: 0.0836\n",
      "Epoch 3/30\n",
      "931/931 [==============================] - 8s 9ms/step - loss: 0.1972 - SA: 0.0941 - val_loss: 0.3044 - val_SA: 0.1007\n",
      "Epoch 4/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.1314 - SA: 0.1146 - val_loss: 0.2219 - val_SA: 0.1176\n",
      "Epoch 5/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0959 - SA: 0.1379 - val_loss: 0.1719 - val_SA: 0.1338\n",
      "Epoch 6/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0741 - SA: 0.1603 - val_loss: 0.1507 - val_SA: 0.1432\n",
      "Epoch 7/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0597 - SA: 0.1841 - val_loss: 0.1679 - val_SA: 0.1543\n",
      "Epoch 8/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0494 - SA: 0.2016 - val_loss: 0.1483 - val_SA: 0.1782\n",
      "Epoch 9/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0422 - SA: 0.2274 - val_loss: 0.1467 - val_SA: 0.2008\n",
      "Epoch 10/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0370 - SA: 0.2467 - val_loss: 0.1433 - val_SA: 0.2248\n",
      "Epoch 11/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0322 - SA: 0.2736 - val_loss: 0.1288 - val_SA: 0.2236\n",
      "Epoch 12/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0292 - SA: 0.2922 - val_loss: 0.1280 - val_SA: 0.2220\n",
      "Epoch 13/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0262 - SA: 0.3089 - val_loss: 0.1017 - val_SA: 0.2484\n",
      "Epoch 14/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0241 - SA: 0.3267 - val_loss: 0.1170 - val_SA: 0.2256\n",
      "Epoch 15/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0220 - SA: 0.3366 - val_loss: 0.1060 - val_SA: 0.2396\n",
      "Epoch 16/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0203 - SA: 0.3546 - val_loss: 0.0911 - val_SA: 0.2813\n",
      "Epoch 17/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0190 - SA: 0.3693 - val_loss: 0.0851 - val_SA: 0.2788\n",
      "Epoch 18/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0177 - SA: 0.3844 - val_loss: 0.0837 - val_SA: 0.2851\n",
      "Epoch 19/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0163 - SA: 0.3958 - val_loss: 0.0757 - val_SA: 0.3050\n",
      "Epoch 20/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0153 - SA: 0.4086 - val_loss: 0.0715 - val_SA: 0.3122\n",
      "Epoch 21/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0143 - SA: 0.4154 - val_loss: 0.0769 - val_SA: 0.3072\n",
      "Epoch 22/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0137 - SA: 0.4341 - val_loss: 0.0763 - val_SA: 0.3044\n",
      "Epoch 23/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0128 - SA: 0.4419 - val_loss: 0.0726 - val_SA: 0.3251\n",
      "Epoch 24/30\n",
      "931/931 [==============================] - 7s 7ms/step - loss: 0.0119 - SA: 0.4599 - val_loss: 0.0771 - val_SA: 0.3166\n",
      "Cross-validation: experiment_6 on fold 1\n",
      "Epoch 1/30\n",
      "931/931 [==============================] - 11s 9ms/step - loss: 0.5785 - SA: 0.0588 - val_loss: 0.2729 - val_SA: 0.0783\n",
      "Epoch 2/30\n",
      "931/931 [==============================] - 8s 9ms/step - loss: 0.3095 - SA: 0.0811 - val_loss: 0.1795 - val_SA: 0.0977\n",
      "Epoch 3/30\n",
      "931/931 [==============================] - 8s 9ms/step - loss: 0.1906 - SA: 0.0984 - val_loss: 0.1255 - val_SA: 0.1242\n",
      "Epoch 4/30\n",
      "931/931 [==============================] - 9s 9ms/step - loss: 0.1304 - SA: 0.1186 - val_loss: 0.0876 - val_SA: 0.1513\n",
      "Epoch 5/30\n",
      "931/931 [==============================] - 8s 9ms/step - loss: 0.0932 - SA: 0.1416 - val_loss: 0.0687 - val_SA: 0.2051\n",
      "Epoch 6/30\n",
      "931/931 [==============================] - 9s 9ms/step - loss: 0.0700 - SA: 0.1699 - val_loss: 0.0639 - val_SA: 0.2369\n",
      "Epoch 7/30\n",
      "931/931 [==============================] - 9s 9ms/step - loss: 0.0556 - SA: 0.1932 - val_loss: 0.0606 - val_SA: 0.2540\n",
      "Epoch 8/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0467 - SA: 0.2249 - val_loss: 0.0586 - val_SA: 0.2619\n",
      "Epoch 9/30\n",
      "931/931 [==============================] - 8s 9ms/step - loss: 0.0401 - SA: 0.2534 - val_loss: 0.0577 - val_SA: 0.2578\n",
      "Epoch 10/30\n",
      "931/931 [==============================] - 9s 9ms/step - loss: 0.0362 - SA: 0.2712 - val_loss: 0.0562 - val_SA: 0.2687\n",
      "Epoch 11/30\n",
      "931/931 [==============================] - 9s 9ms/step - loss: 0.0323 - SA: 0.2919 - val_loss: 0.0557 - val_SA: 0.2676\n",
      "Epoch 12/30\n",
      "931/931 [==============================] - 8s 9ms/step - loss: 0.0293 - SA: 0.3104 - val_loss: 0.0550 - val_SA: 0.2730\n",
      "Epoch 13/30\n",
      "931/931 [==============================] - 9s 9ms/step - loss: 0.0269 - SA: 0.3282 - val_loss: 0.0541 - val_SA: 0.2799\n",
      "Epoch 14/30\n",
      "931/931 [==============================] - 8s 9ms/step - loss: 0.0246 - SA: 0.3446 - val_loss: 0.0515 - val_SA: 0.2944\n",
      "Epoch 15/30\n",
      "931/931 [==============================] - 8s 9ms/step - loss: 0.0228 - SA: 0.3524 - val_loss: 0.0513 - val_SA: 0.3015\n",
      "Epoch 16/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0213 - SA: 0.3680 - val_loss: 0.0500 - val_SA: 0.3044\n",
      "Epoch 17/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0196 - SA: 0.3824 - val_loss: 0.0484 - val_SA: 0.3323\n",
      "Epoch 18/30\n",
      "931/931 [==============================] - 8s 9ms/step - loss: 0.0183 - SA: 0.3971 - val_loss: 0.0474 - val_SA: 0.3298\n",
      "Epoch 19/30\n",
      "931/931 [==============================] - 8s 9ms/step - loss: 0.0171 - SA: 0.4060 - val_loss: 0.0468 - val_SA: 0.3401\n",
      "Epoch 20/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0160 - SA: 0.4252 - val_loss: 0.0454 - val_SA: 0.3614\n",
      "Epoch 21/30\n",
      "931/931 [==============================] - 8s 9ms/step - loss: 0.0153 - SA: 0.4295 - val_loss: 0.0437 - val_SA: 0.3795\n",
      "Epoch 22/30\n",
      "931/931 [==============================] - 8s 9ms/step - loss: 0.0146 - SA: 0.4457 - val_loss: 0.0433 - val_SA: 0.3875\n",
      "Epoch 23/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0137 - SA: 0.4489 - val_loss: 0.0426 - val_SA: 0.3902\n",
      "Epoch 24/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0133 - SA: 0.4560 - val_loss: 0.0416 - val_SA: 0.4008\n",
      "Epoch 25/30\n",
      "931/931 [==============================] - 8s 9ms/step - loss: 0.0125 - SA: 0.4697 - val_loss: 0.0414 - val_SA: 0.3967\n",
      "Epoch 26/30\n",
      "931/931 [==============================] - 8s 9ms/step - loss: 0.0121 - SA: 0.4789 - val_loss: 0.0395 - val_SA: 0.4046\n",
      "Epoch 27/30\n",
      "931/931 [==============================] - 8s 9ms/step - loss: 0.0117 - SA: 0.4898 - val_loss: 0.0389 - val_SA: 0.4030\n",
      "Epoch 28/30\n",
      "931/931 [==============================] - 8s 9ms/step - loss: 0.0111 - SA: 0.4950 - val_loss: 0.0397 - val_SA: 0.4142\n",
      "Epoch 29/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0106 - SA: 0.5027 - val_loss: 0.0371 - val_SA: 0.4125\n",
      "Epoch 30/30\n",
      "931/931 [==============================] - 8s 9ms/step - loss: 0.0103 - SA: 0.5116 - val_loss: 0.0373 - val_SA: 0.4189\n",
      "Cross-validation: experiment_6 on fold 2\n",
      "Epoch 1/30\n",
      "931/931 [==============================] - 10s 9ms/step - loss: 0.6002 - SA: 0.0579 - val_loss: 0.3512 - val_SA: 0.0577\n",
      "Epoch 2/30\n",
      "931/931 [==============================] - 7s 7ms/step - loss: 0.3007 - SA: 0.0814 - val_loss: 0.2138 - val_SA: 0.0841\n",
      "Epoch 3/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.1852 - SA: 0.1005 - val_loss: 0.1286 - val_SA: 0.1156\n",
      "Epoch 4/30\n",
      "931/931 [==============================] - 7s 7ms/step - loss: 0.1223 - SA: 0.1258 - val_loss: 0.0776 - val_SA: 0.1610\n",
      "Epoch 5/30\n",
      "931/931 [==============================] - 7s 7ms/step - loss: 0.0907 - SA: 0.1465 - val_loss: 0.0599 - val_SA: 0.2123\n",
      "Epoch 6/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0693 - SA: 0.1720 - val_loss: 0.0564 - val_SA: 0.2195\n",
      "Epoch 7/30\n",
      "931/931 [==============================] - 7s 7ms/step - loss: 0.0567 - SA: 0.1964 - val_loss: 0.0522 - val_SA: 0.2356\n",
      "Epoch 8/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0484 - SA: 0.2204 - val_loss: 0.0470 - val_SA: 0.2655\n",
      "Epoch 9/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0419 - SA: 0.2443 - val_loss: 0.0461 - val_SA: 0.2692\n",
      "Epoch 10/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0372 - SA: 0.2652 - val_loss: 0.0425 - val_SA: 0.3056\n",
      "Epoch 11/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0335 - SA: 0.2875 - val_loss: 0.0410 - val_SA: 0.3319\n",
      "Epoch 12/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0302 - SA: 0.3041 - val_loss: 0.0419 - val_SA: 0.3410\n",
      "Epoch 13/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0272 - SA: 0.3224 - val_loss: 0.0400 - val_SA: 0.3414\n",
      "Epoch 14/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0252 - SA: 0.3368 - val_loss: 0.0400 - val_SA: 0.3529\n",
      "Epoch 15/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0232 - SA: 0.3480 - val_loss: 0.0383 - val_SA: 0.3628\n",
      "Epoch 16/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0216 - SA: 0.3643 - val_loss: 0.0362 - val_SA: 0.3961\n",
      "Epoch 17/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0201 - SA: 0.3755 - val_loss: 0.0366 - val_SA: 0.3983\n",
      "Epoch 18/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0185 - SA: 0.3868 - val_loss: 0.0353 - val_SA: 0.3900\n",
      "Epoch 19/30\n",
      "931/931 [==============================] - 7s 7ms/step - loss: 0.0178 - SA: 0.3924 - val_loss: 0.0333 - val_SA: 0.4054\n",
      "Epoch 20/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0165 - SA: 0.4026 - val_loss: 0.0332 - val_SA: 0.4160\n",
      "Epoch 21/30\n",
      "931/931 [==============================] - 7s 7ms/step - loss: 0.0157 - SA: 0.4180 - val_loss: 0.0323 - val_SA: 0.4301\n",
      "Epoch 22/30\n",
      "931/931 [==============================] - 7s 7ms/step - loss: 0.0148 - SA: 0.4295 - val_loss: 0.0321 - val_SA: 0.4311\n",
      "Epoch 23/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0142 - SA: 0.4374 - val_loss: 0.0311 - val_SA: 0.4433\n",
      "Epoch 24/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0135 - SA: 0.4468 - val_loss: 0.0294 - val_SA: 0.4493\n",
      "Epoch 25/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0128 - SA: 0.4564 - val_loss: 0.0272 - val_SA: 0.4587\n",
      "Epoch 26/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0122 - SA: 0.4591 - val_loss: 0.0280 - val_SA: 0.4594\n",
      "Epoch 27/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0120 - SA: 0.4691 - val_loss: 0.0283 - val_SA: 0.4606\n",
      "Epoch 28/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0115 - SA: 0.4795 - val_loss: 0.0264 - val_SA: 0.4658\n",
      "Epoch 29/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0109 - SA: 0.4858 - val_loss: 0.0260 - val_SA: 0.4622\n",
      "Epoch 30/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0105 - SA: 0.4950 - val_loss: 0.0256 - val_SA: 0.4723\n",
      "Cross-validation: experiment_6 on fold 3\n",
      "Epoch 1/30\n",
      "931/931 [==============================] - 10s 8ms/step - loss: 0.5805 - SA: 0.0560 - val_loss: 0.3555 - val_SA: 0.0526\n",
      "Epoch 2/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.3042 - SA: 0.0774 - val_loss: 0.3013 - val_SA: 0.0547\n",
      "Epoch 3/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.1958 - SA: 0.0957 - val_loss: 0.1976 - val_SA: 0.0633\n",
      "Epoch 4/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.1339 - SA: 0.1181 - val_loss: 0.1262 - val_SA: 0.0798\n",
      "Epoch 5/30\n",
      "931/931 [==============================] - 7s 7ms/step - loss: 0.0993 - SA: 0.1403 - val_loss: 0.0821 - val_SA: 0.1109\n",
      "Epoch 6/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0749 - SA: 0.1630 - val_loss: 0.0573 - val_SA: 0.1546\n",
      "Epoch 7/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0603 - SA: 0.1893 - val_loss: 0.0539 - val_SA: 0.1533\n",
      "Epoch 8/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0512 - SA: 0.2168 - val_loss: 0.0469 - val_SA: 0.1663\n",
      "Epoch 9/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0440 - SA: 0.2382 - val_loss: 0.0427 - val_SA: 0.1831\n",
      "Epoch 10/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0392 - SA: 0.2582 - val_loss: 0.0411 - val_SA: 0.1960\n",
      "Epoch 11/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0355 - SA: 0.2799 - val_loss: 0.0399 - val_SA: 0.2093\n",
      "Epoch 12/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0319 - SA: 0.2980 - val_loss: 0.0376 - val_SA: 0.2140\n",
      "Epoch 13/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0293 - SA: 0.3086 - val_loss: 0.0354 - val_SA: 0.2508\n",
      "Epoch 14/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0269 - SA: 0.3285 - val_loss: 0.0357 - val_SA: 0.2353\n",
      "Epoch 15/30\n",
      "931/931 [==============================] - 7s 7ms/step - loss: 0.0252 - SA: 0.3444 - val_loss: 0.0347 - val_SA: 0.2512\n",
      "Epoch 16/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0234 - SA: 0.3538 - val_loss: 0.0352 - val_SA: 0.2412\n",
      "Epoch 17/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0221 - SA: 0.3571 - val_loss: 0.0317 - val_SA: 0.2881\n",
      "Epoch 18/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0205 - SA: 0.3777 - val_loss: 0.0348 - val_SA: 0.2394\n",
      "Epoch 19/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0192 - SA: 0.3840 - val_loss: 0.0313 - val_SA: 0.2891\n",
      "Epoch 20/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0183 - SA: 0.3959 - val_loss: 0.0304 - val_SA: 0.2850\n",
      "Epoch 21/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0176 - SA: 0.4033 - val_loss: 0.0273 - val_SA: 0.3635\n",
      "Epoch 22/30\n",
      "931/931 [==============================] - 7s 7ms/step - loss: 0.0165 - SA: 0.4090 - val_loss: 0.0286 - val_SA: 0.3190\n",
      "Epoch 23/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0156 - SA: 0.4235 - val_loss: 0.0276 - val_SA: 0.3268\n",
      "Epoch 24/30\n",
      "931/931 [==============================] - 7s 7ms/step - loss: 0.0149 - SA: 0.4316 - val_loss: 0.0267 - val_SA: 0.3823\n",
      "Epoch 25/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0142 - SA: 0.4431 - val_loss: 0.0245 - val_SA: 0.4311\n",
      "Epoch 26/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0136 - SA: 0.4443 - val_loss: 0.0245 - val_SA: 0.4194\n",
      "Epoch 27/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0134 - SA: 0.4546 - val_loss: 0.0220 - val_SA: 0.4520\n",
      "Epoch 28/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0124 - SA: 0.4611 - val_loss: 0.0237 - val_SA: 0.3977\n",
      "Epoch 29/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0121 - SA: 0.4735 - val_loss: 0.0222 - val_SA: 0.4505\n",
      "Epoch 30/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0118 - SA: 0.4720 - val_loss: 0.0234 - val_SA: 0.4065\n",
      "Cross-validation: experiment_6 on fold 4\n",
      "Epoch 1/30\n",
      "931/931 [==============================] - 11s 9ms/step - loss: 0.5851 - SA: 0.0574 - val_loss: 0.6032 - val_SA: 0.0740\n",
      "Epoch 2/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.3027 - SA: 0.0762 - val_loss: 0.4805 - val_SA: 0.0769\n",
      "Epoch 3/30\n",
      "931/931 [==============================] - 8s 9ms/step - loss: 0.1940 - SA: 0.0961 - val_loss: 0.3524 - val_SA: 0.0969\n",
      "Epoch 4/30\n",
      "931/931 [==============================] - 8s 9ms/step - loss: 0.1316 - SA: 0.1167 - val_loss: 0.2391 - val_SA: 0.1181\n",
      "Epoch 5/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0965 - SA: 0.1400 - val_loss: 0.1864 - val_SA: 0.1302\n",
      "Epoch 6/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0752 - SA: 0.1574 - val_loss: 0.1704 - val_SA: 0.1406\n",
      "Epoch 7/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0604 - SA: 0.1791 - val_loss: 0.1735 - val_SA: 0.1307\n",
      "Epoch 8/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0500 - SA: 0.2034 - val_loss: 0.1774 - val_SA: 0.1389\n",
      "Epoch 9/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0425 - SA: 0.2276 - val_loss: 0.1619 - val_SA: 0.1644\n",
      "Epoch 10/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0375 - SA: 0.2451 - val_loss: 0.1430 - val_SA: 0.1931\n",
      "Epoch 11/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0330 - SA: 0.2671 - val_loss: 0.1183 - val_SA: 0.2185\n",
      "Epoch 12/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0296 - SA: 0.2881 - val_loss: 0.1192 - val_SA: 0.2210\n",
      "Epoch 13/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0267 - SA: 0.3066 - val_loss: 0.0991 - val_SA: 0.2494\n",
      "Epoch 14/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0245 - SA: 0.3258 - val_loss: 0.1061 - val_SA: 0.2477\n",
      "Epoch 15/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0228 - SA: 0.3341 - val_loss: 0.0956 - val_SA: 0.2565\n",
      "Epoch 16/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0211 - SA: 0.3511 - val_loss: 0.0936 - val_SA: 0.2486\n",
      "Epoch 17/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0197 - SA: 0.3632 - val_loss: 0.0852 - val_SA: 0.2573\n",
      "Epoch 18/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0182 - SA: 0.3759 - val_loss: 0.0870 - val_SA: 0.2664\n",
      "Epoch 19/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0171 - SA: 0.3855 - val_loss: 0.0838 - val_SA: 0.2744\n",
      "Epoch 20/30\n",
      "931/931 [==============================] - 8s 9ms/step - loss: 0.0161 - SA: 0.3956 - val_loss: 0.0802 - val_SA: 0.2906\n",
      "Epoch 21/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0150 - SA: 0.4078 - val_loss: 0.0817 - val_SA: 0.2813\n",
      "Epoch 22/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0143 - SA: 0.4194 - val_loss: 0.0805 - val_SA: 0.2902\n",
      "Epoch 23/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0134 - SA: 0.4276 - val_loss: 0.0779 - val_SA: 0.2938\n",
      "Epoch 24/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0127 - SA: 0.4395 - val_loss: 0.0789 - val_SA: 0.3080\n",
      "Epoch 25/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0119 - SA: 0.4493 - val_loss: 0.0720 - val_SA: 0.3037\n",
      "Epoch 26/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0115 - SA: 0.4588 - val_loss: 0.0702 - val_SA: 0.3270\n",
      "Epoch 27/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0109 - SA: 0.4655 - val_loss: 0.0718 - val_SA: 0.3148\n",
      "Epoch 28/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0105 - SA: 0.4819 - val_loss: 0.0665 - val_SA: 0.3320\n",
      "Epoch 29/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0101 - SA: 0.4792 - val_loss: 0.0649 - val_SA: 0.3433\n",
      "Epoch 30/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0098 - SA: 0.4885 - val_loss: 0.0597 - val_SA: 0.3464\n",
      "Cross-validation: experiment_7 on fold 1\n",
      "Epoch 1/30\n",
      "931/931 [==============================] - 10s 8ms/step - loss: 0.5853 - SA: 0.0579 - val_loss: 0.2678 - val_SA: 0.0811\n",
      "Epoch 2/30\n",
      "931/931 [==============================] - 8s 9ms/step - loss: 0.3014 - SA: 0.0794 - val_loss: 0.1672 - val_SA: 0.1074\n",
      "Epoch 3/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.1893 - SA: 0.0981 - val_loss: 0.1158 - val_SA: 0.1369\n",
      "Epoch 4/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.1257 - SA: 0.1224 - val_loss: 0.0898 - val_SA: 0.1509\n",
      "Epoch 5/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0898 - SA: 0.1466 - val_loss: 0.0799 - val_SA: 0.1799\n",
      "Epoch 6/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0690 - SA: 0.1702 - val_loss: 0.0718 - val_SA: 0.1998\n",
      "Epoch 7/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0550 - SA: 0.1981 - val_loss: 0.0669 - val_SA: 0.2193\n",
      "Epoch 8/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0462 - SA: 0.2260 - val_loss: 0.0617 - val_SA: 0.2361\n",
      "Epoch 9/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0402 - SA: 0.2516 - val_loss: 0.0599 - val_SA: 0.2405\n",
      "Epoch 10/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0354 - SA: 0.2725 - val_loss: 0.0574 - val_SA: 0.2672\n",
      "Epoch 11/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0321 - SA: 0.2929 - val_loss: 0.0582 - val_SA: 0.2683\n",
      "Epoch 12/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0292 - SA: 0.3066 - val_loss: 0.0565 - val_SA: 0.2758\n",
      "Epoch 13/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0265 - SA: 0.3251 - val_loss: 0.0545 - val_SA: 0.2865\n",
      "Epoch 14/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0240 - SA: 0.3420 - val_loss: 0.0531 - val_SA: 0.2854\n",
      "Epoch 15/30\n",
      "931/931 [==============================] - 8s 9ms/step - loss: 0.0224 - SA: 0.3570 - val_loss: 0.0513 - val_SA: 0.3028\n",
      "Epoch 16/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0207 - SA: 0.3683 - val_loss: 0.0523 - val_SA: 0.2844\n",
      "Epoch 17/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0193 - SA: 0.3791 - val_loss: 0.0495 - val_SA: 0.3083\n",
      "Epoch 18/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0182 - SA: 0.3942 - val_loss: 0.0462 - val_SA: 0.3292\n",
      "Epoch 19/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0169 - SA: 0.4045 - val_loss: 0.0465 - val_SA: 0.3198\n",
      "Epoch 20/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0160 - SA: 0.4208 - val_loss: 0.0467 - val_SA: 0.3382\n",
      "Epoch 21/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0155 - SA: 0.4225 - val_loss: 0.0446 - val_SA: 0.3375\n",
      "Epoch 22/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0143 - SA: 0.4342 - val_loss: 0.0432 - val_SA: 0.3668\n",
      "Epoch 23/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0139 - SA: 0.4506 - val_loss: 0.0409 - val_SA: 0.3687\n",
      "Epoch 24/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0133 - SA: 0.4572 - val_loss: 0.0401 - val_SA: 0.3577\n",
      "Epoch 25/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0127 - SA: 0.4615 - val_loss: 0.0398 - val_SA: 0.3615\n",
      "Epoch 26/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0121 - SA: 0.4719 - val_loss: 0.0385 - val_SA: 0.3807\n",
      "Epoch 27/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0116 - SA: 0.4849 - val_loss: 0.0375 - val_SA: 0.3851\n",
      "Epoch 28/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0111 - SA: 0.4904 - val_loss: 0.0361 - val_SA: 0.3814\n",
      "Epoch 29/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0107 - SA: 0.4981 - val_loss: 0.0363 - val_SA: 0.3985\n",
      "Epoch 30/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0104 - SA: 0.5000 - val_loss: 0.0353 - val_SA: 0.4045\n",
      "Cross-validation: experiment_7 on fold 2\n",
      "Epoch 1/30\n",
      "931/931 [==============================] - 10s 8ms/step - loss: 0.5877 - SA: 0.0594 - val_loss: 0.2778 - val_SA: 0.0708\n",
      "Epoch 2/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.2986 - SA: 0.0760 - val_loss: 0.1383 - val_SA: 0.1090\n",
      "Epoch 3/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.1781 - SA: 0.1065 - val_loss: 0.1002 - val_SA: 0.1365\n",
      "Epoch 4/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.1211 - SA: 0.1271 - val_loss: 0.0770 - val_SA: 0.1680\n",
      "Epoch 5/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0894 - SA: 0.1481 - val_loss: 0.0728 - val_SA: 0.1806\n",
      "Epoch 6/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0683 - SA: 0.1723 - val_loss: 0.0644 - val_SA: 0.2044\n",
      "Epoch 7/30\n",
      "931/931 [==============================] - 7s 7ms/step - loss: 0.0554 - SA: 0.1989 - val_loss: 0.0587 - val_SA: 0.2262\n",
      "Epoch 8/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0461 - SA: 0.2314 - val_loss: 0.0530 - val_SA: 0.2637\n",
      "Epoch 9/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0402 - SA: 0.2513 - val_loss: 0.0506 - val_SA: 0.2720\n",
      "Epoch 10/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0358 - SA: 0.2771 - val_loss: 0.0471 - val_SA: 0.2928\n",
      "Epoch 11/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0322 - SA: 0.2953 - val_loss: 0.0440 - val_SA: 0.3255\n",
      "Epoch 12/30\n",
      "931/931 [==============================] - 7s 7ms/step - loss: 0.0289 - SA: 0.3118 - val_loss: 0.0430 - val_SA: 0.3202\n",
      "Epoch 13/30\n",
      "931/931 [==============================] - 7s 7ms/step - loss: 0.0264 - SA: 0.3319 - val_loss: 0.0416 - val_SA: 0.3360\n",
      "Epoch 14/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0244 - SA: 0.3405 - val_loss: 0.0429 - val_SA: 0.3085\n",
      "Epoch 15/30\n",
      "931/931 [==============================] - 7s 7ms/step - loss: 0.0225 - SA: 0.3515 - val_loss: 0.0414 - val_SA: 0.3505\n",
      "Epoch 16/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0210 - SA: 0.3658 - val_loss: 0.0402 - val_SA: 0.3360\n",
      "Epoch 17/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0195 - SA: 0.3815 - val_loss: 0.0390 - val_SA: 0.3578\n",
      "Epoch 18/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0184 - SA: 0.3889 - val_loss: 0.0372 - val_SA: 0.3535\n",
      "Epoch 19/30\n",
      "931/931 [==============================] - 7s 7ms/step - loss: 0.0170 - SA: 0.4045 - val_loss: 0.0359 - val_SA: 0.3873\n",
      "Epoch 20/30\n",
      "931/931 [==============================] - 7s 7ms/step - loss: 0.0163 - SA: 0.4111 - val_loss: 0.0342 - val_SA: 0.3752\n",
      "Epoch 21/30\n",
      "931/931 [==============================] - 7s 7ms/step - loss: 0.0152 - SA: 0.4230 - val_loss: 0.0329 - val_SA: 0.3845\n",
      "Epoch 22/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0143 - SA: 0.4321 - val_loss: 0.0322 - val_SA: 0.3965\n",
      "Epoch 23/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0137 - SA: 0.4374 - val_loss: 0.0331 - val_SA: 0.3859\n",
      "Epoch 24/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0128 - SA: 0.4542 - val_loss: 0.0309 - val_SA: 0.3919\n",
      "Epoch 25/30\n",
      "931/931 [==============================] - 7s 7ms/step - loss: 0.0124 - SA: 0.4587 - val_loss: 0.0299 - val_SA: 0.4190\n",
      "Epoch 26/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0118 - SA: 0.4640 - val_loss: 0.0288 - val_SA: 0.4244\n",
      "Epoch 27/30\n",
      "931/931 [==============================] - 7s 7ms/step - loss: 0.0115 - SA: 0.4739 - val_loss: 0.0293 - val_SA: 0.4490\n",
      "Epoch 28/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0112 - SA: 0.4783 - val_loss: 0.0277 - val_SA: 0.4541\n",
      "Epoch 29/30\n",
      "931/931 [==============================] - 7s 7ms/step - loss: 0.0104 - SA: 0.4849 - val_loss: 0.0277 - val_SA: 0.4467\n",
      "Epoch 30/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0102 - SA: 0.4901 - val_loss: 0.0264 - val_SA: 0.4735\n",
      "Cross-validation: experiment_7 on fold 3\n",
      "Epoch 1/30\n",
      "931/931 [==============================] - 10s 8ms/step - loss: 0.5885 - SA: 0.0573 - val_loss: 0.3096 - val_SA: 0.0602\n",
      "Epoch 2/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.3069 - SA: 0.0770 - val_loss: 0.2081 - val_SA: 0.0751\n",
      "Epoch 3/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.1869 - SA: 0.0974 - val_loss: 0.1454 - val_SA: 0.0826\n",
      "Epoch 4/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.1265 - SA: 0.1204 - val_loss: 0.1116 - val_SA: 0.0968\n",
      "Epoch 5/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0914 - SA: 0.1424 - val_loss: 0.0769 - val_SA: 0.1366\n",
      "Epoch 6/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0722 - SA: 0.1656 - val_loss: 0.0530 - val_SA: 0.1821\n",
      "Epoch 7/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0586 - SA: 0.1897 - val_loss: 0.0407 - val_SA: 0.2459\n",
      "Epoch 8/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0490 - SA: 0.2187 - val_loss: 0.0379 - val_SA: 0.2395\n",
      "Epoch 9/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0426 - SA: 0.2435 - val_loss: 0.0375 - val_SA: 0.2352\n",
      "Epoch 10/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0380 - SA: 0.2618 - val_loss: 0.0372 - val_SA: 0.2456\n",
      "Epoch 11/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0342 - SA: 0.2848 - val_loss: 0.0358 - val_SA: 0.2698\n",
      "Epoch 12/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0310 - SA: 0.3012 - val_loss: 0.0340 - val_SA: 0.2950\n",
      "Epoch 13/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0286 - SA: 0.3204 - val_loss: 0.0341 - val_SA: 0.2535\n",
      "Epoch 14/30\n",
      "931/931 [==============================] - 7s 7ms/step - loss: 0.0260 - SA: 0.3347 - val_loss: 0.0334 - val_SA: 0.2600\n",
      "Epoch 15/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0245 - SA: 0.3498 - val_loss: 0.0314 - val_SA: 0.2952\n",
      "Epoch 16/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0228 - SA: 0.3561 - val_loss: 0.0324 - val_SA: 0.2781\n",
      "Epoch 17/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0210 - SA: 0.3772 - val_loss: 0.0292 - val_SA: 0.3321\n",
      "Epoch 18/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0198 - SA: 0.3861 - val_loss: 0.0283 - val_SA: 0.3569\n",
      "Epoch 19/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0188 - SA: 0.3934 - val_loss: 0.0296 - val_SA: 0.2888\n",
      "Epoch 20/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0179 - SA: 0.3992 - val_loss: 0.0284 - val_SA: 0.3482\n",
      "Epoch 21/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0168 - SA: 0.4073 - val_loss: 0.0274 - val_SA: 0.3477\n",
      "Epoch 22/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0160 - SA: 0.4146 - val_loss: 0.0250 - val_SA: 0.4118\n",
      "Epoch 23/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0154 - SA: 0.4283 - val_loss: 0.0248 - val_SA: 0.4331\n",
      "Epoch 24/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0147 - SA: 0.4284 - val_loss: 0.0235 - val_SA: 0.4502\n",
      "Epoch 25/30\n",
      "931/931 [==============================] - 7s 7ms/step - loss: 0.0139 - SA: 0.4347 - val_loss: 0.0245 - val_SA: 0.4243\n",
      "Epoch 26/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0132 - SA: 0.4458 - val_loss: 0.0231 - val_SA: 0.4730\n",
      "Epoch 27/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0127 - SA: 0.4528 - val_loss: 0.0237 - val_SA: 0.4742\n",
      "Epoch 28/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0123 - SA: 0.4550 - val_loss: 0.0227 - val_SA: 0.4839\n",
      "Epoch 29/30\n",
      "931/931 [==============================] - 7s 7ms/step - loss: 0.0119 - SA: 0.4632 - val_loss: 0.0220 - val_SA: 0.5050\n",
      "Epoch 30/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0115 - SA: 0.4724 - val_loss: 0.0208 - val_SA: 0.4943\n",
      "Cross-validation: experiment_7 on fold 4\n",
      "Epoch 1/30\n",
      "931/931 [==============================] - 10s 8ms/step - loss: 0.5817 - SA: 0.0589 - val_loss: 0.5449 - val_SA: 0.0722\n",
      "Epoch 2/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.3028 - SA: 0.0755 - val_loss: 0.4406 - val_SA: 0.0862\n",
      "Epoch 3/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.1943 - SA: 0.0961 - val_loss: 0.3154 - val_SA: 0.1121\n",
      "Epoch 4/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.1303 - SA: 0.1156 - val_loss: 0.2652 - val_SA: 0.1289\n",
      "Epoch 5/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0935 - SA: 0.1418 - val_loss: 0.2149 - val_SA: 0.1344\n",
      "Epoch 6/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0713 - SA: 0.1648 - val_loss: 0.1921 - val_SA: 0.1536\n",
      "Epoch 7/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0577 - SA: 0.1860 - val_loss: 0.1641 - val_SA: 0.1701\n",
      "Epoch 8/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0479 - SA: 0.2108 - val_loss: 0.1570 - val_SA: 0.2019\n",
      "Epoch 9/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0406 - SA: 0.2369 - val_loss: 0.1356 - val_SA: 0.2081\n",
      "Epoch 10/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0358 - SA: 0.2600 - val_loss: 0.1483 - val_SA: 0.2047\n",
      "Epoch 11/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0325 - SA: 0.2769 - val_loss: 0.1307 - val_SA: 0.2356\n",
      "Epoch 12/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0295 - SA: 0.2965 - val_loss: 0.1326 - val_SA: 0.2387\n",
      "Epoch 13/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0266 - SA: 0.3197 - val_loss: 0.1532 - val_SA: 0.2277\n",
      "Epoch 14/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0245 - SA: 0.3267 - val_loss: 0.1422 - val_SA: 0.2405\n",
      "Epoch 15/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0227 - SA: 0.3412 - val_loss: 0.1243 - val_SA: 0.2524\n",
      "Epoch 16/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0208 - SA: 0.3601 - val_loss: 0.1179 - val_SA: 0.2469\n",
      "Epoch 17/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0195 - SA: 0.3675 - val_loss: 0.1207 - val_SA: 0.2420\n",
      "Epoch 18/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0182 - SA: 0.3890 - val_loss: 0.1054 - val_SA: 0.2760\n",
      "Epoch 19/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0168 - SA: 0.3983 - val_loss: 0.1145 - val_SA: 0.2556\n",
      "Epoch 20/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0158 - SA: 0.4039 - val_loss: 0.1127 - val_SA: 0.2564\n",
      "Epoch 21/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0149 - SA: 0.4216 - val_loss: 0.0998 - val_SA: 0.2719\n",
      "Epoch 22/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0143 - SA: 0.4305 - val_loss: 0.0929 - val_SA: 0.2820\n",
      "Epoch 23/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0133 - SA: 0.4421 - val_loss: 0.0994 - val_SA: 0.2681\n",
      "Epoch 24/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0125 - SA: 0.4481 - val_loss: 0.1049 - val_SA: 0.2571\n",
      "Epoch 25/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0119 - SA: 0.4595 - val_loss: 0.0830 - val_SA: 0.3010\n",
      "Epoch 26/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0113 - SA: 0.4677 - val_loss: 0.0908 - val_SA: 0.2796\n",
      "Epoch 27/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0110 - SA: 0.4785 - val_loss: 0.0828 - val_SA: 0.2942\n",
      "Epoch 28/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0103 - SA: 0.4869 - val_loss: 0.0911 - val_SA: 0.2819\n",
      "Epoch 29/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.0100 - SA: 0.4925 - val_loss: 0.0800 - val_SA: 0.2832\n",
      "Epoch 30/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.0097 - SA: 0.4966 - val_loss: 0.0733 - val_SA: 0.3060\n",
      "Cross-validation: experiment_8 on fold 1\n",
      "Epoch 1/30\n",
      "931/931 [==============================] - 10s 8ms/step - loss: 0.8886 - SA: 0.0490 - val_loss: 0.2637 - val_SA: 0.0816\n",
      "Epoch 2/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.7498 - SA: 0.0500 - val_loss: 0.2521 - val_SA: 0.0823\n",
      "Epoch 3/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.6765 - SA: 0.0537 - val_loss: 0.2543 - val_SA: 0.0838\n",
      "Epoch 4/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.6153 - SA: 0.0539 - val_loss: 0.2475 - val_SA: 0.0805\n",
      "Epoch 5/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.5688 - SA: 0.0566 - val_loss: 0.2408 - val_SA: 0.0844\n",
      "Epoch 6/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.5227 - SA: 0.0611 - val_loss: 0.2466 - val_SA: 0.0840\n",
      "Epoch 7/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.4770 - SA: 0.0627 - val_loss: 0.2432 - val_SA: 0.0881\n",
      "Epoch 8/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.4462 - SA: 0.0628 - val_loss: 0.2409 - val_SA: 0.0856\n",
      "Epoch 9/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.4084 - SA: 0.0669 - val_loss: 0.2416 - val_SA: 0.0793\n",
      "Cross-validation: experiment_8 on fold 2\n",
      "Epoch 1/30\n",
      "931/931 [==============================] - 10s 8ms/step - loss: 0.8849 - SA: 0.0495 - val_loss: 0.3122 - val_SA: 0.0693\n",
      "Epoch 2/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.7562 - SA: 0.0494 - val_loss: 0.2728 - val_SA: 0.0755\n",
      "Epoch 3/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.6857 - SA: 0.0530 - val_loss: 0.2660 - val_SA: 0.0778\n",
      "Epoch 4/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.6262 - SA: 0.0557 - val_loss: 0.2585 - val_SA: 0.0777\n",
      "Epoch 5/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.5680 - SA: 0.0580 - val_loss: 0.2778 - val_SA: 0.0744\n",
      "Epoch 6/30\n",
      "931/931 [==============================] - 7s 7ms/step - loss: 0.5223 - SA: 0.0579 - val_loss: 0.2698 - val_SA: 0.0714\n",
      "Epoch 7/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.4852 - SA: 0.0613 - val_loss: 0.2746 - val_SA: 0.0705\n",
      "Epoch 8/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.4428 - SA: 0.0655 - val_loss: 0.2749 - val_SA: 0.0716\n",
      "Cross-validation: experiment_8 on fold 3\n",
      "Epoch 1/30\n",
      "931/931 [==============================] - 10s 8ms/step - loss: 0.8834 - SA: 0.0497 - val_loss: 0.3447 - val_SA: 0.0629\n",
      "Epoch 2/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.7489 - SA: 0.0510 - val_loss: 0.2778 - val_SA: 0.0708\n",
      "Epoch 3/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.6874 - SA: 0.0529 - val_loss: 0.2708 - val_SA: 0.0761\n",
      "Epoch 4/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.6246 - SA: 0.0547 - val_loss: 0.2781 - val_SA: 0.0694\n",
      "Epoch 5/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.5732 - SA: 0.0559 - val_loss: 0.2745 - val_SA: 0.0691\n",
      "Epoch 6/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.5243 - SA: 0.0575 - val_loss: 0.2840 - val_SA: 0.0665\n",
      "Epoch 7/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.4820 - SA: 0.0599 - val_loss: 0.3045 - val_SA: 0.0610\n",
      "Cross-validation: experiment_8 on fold 4\n",
      "Epoch 1/30\n",
      "931/931 [==============================] - 10s 9ms/step - loss: 0.8927 - SA: 0.0506 - val_loss: 1.9198 - val_SA: 0.0477\n",
      "Epoch 2/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.7483 - SA: 0.0514 - val_loss: 1.1903 - val_SA: 0.0533\n",
      "Epoch 3/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.6822 - SA: 0.0524 - val_loss: 0.9318 - val_SA: 0.0543\n",
      "Epoch 4/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.6221 - SA: 0.0546 - val_loss: 0.8553 - val_SA: 0.0592\n",
      "Epoch 5/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.5645 - SA: 0.0561 - val_loss: 0.7800 - val_SA: 0.0610\n",
      "Epoch 6/30\n",
      "931/931 [==============================] - 7s 8ms/step - loss: 0.5226 - SA: 0.0592 - val_loss: 0.7069 - val_SA: 0.0674\n",
      "Epoch 7/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.4813 - SA: 0.0624 - val_loss: 0.6664 - val_SA: 0.0644\n",
      "Epoch 8/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.4464 - SA: 0.0644 - val_loss: 0.6537 - val_SA: 0.0702\n",
      "Epoch 9/30\n",
      "931/931 [==============================] - 7s 7ms/step - loss: 0.4158 - SA: 0.0659 - val_loss: 0.6170 - val_SA: 0.0748\n",
      "Epoch 10/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.3818 - SA: 0.0689 - val_loss: 0.5670 - val_SA: 0.0768\n",
      "Epoch 11/30\n",
      "931/931 [==============================] - 8s 9ms/step - loss: 0.3589 - SA: 0.0692 - val_loss: 0.5776 - val_SA: 0.0801\n",
      "Epoch 12/30\n",
      "931/931 [==============================] - 8s 8ms/step - loss: 0.3367 - SA: 0.0734 - val_loss: 0.5729 - val_SA: 0.0808\n",
      "Epoch 13/30\n",
      "931/931 [==============================] - 8s 9ms/step - loss: 0.3117 - SA: 0.0761 - val_loss: 0.5240 - val_SA: 0.0790\n",
      "Epoch 14/30\n",
      "931/931 [==============================] - 9s 10ms/step - loss: 0.2937 - SA: 0.0770 - val_loss: 0.5330 - val_SA: 0.0781\n",
      "Epoch 15/30\n",
      "931/931 [==============================] - 8s 9ms/step - loss: 0.2756 - SA: 0.0800 - val_loss: 0.5325 - val_SA: 0.0828\n",
      "Epoch 16/30\n",
      "931/931 [==============================] - 9s 9ms/step - loss: 0.2551 - SA: 0.0834 - val_loss: 0.5028 - val_SA: 0.0835\n",
      "Epoch 17/30\n",
      "931/931 [==============================] - 9s 9ms/step - loss: 0.2406 - SA: 0.0856 - val_loss: 0.4891 - val_SA: 0.0887\n",
      "Epoch 18/30\n",
      "931/931 [==============================] - 9s 9ms/step - loss: 0.2254 - SA: 0.0888 - val_loss: 0.4959 - val_SA: 0.0869\n",
      "Epoch 19/30\n",
      "931/931 [==============================] - 9s 9ms/step - loss: 0.2123 - SA: 0.0896 - val_loss: 0.4713 - val_SA: 0.0927\n",
      "Epoch 20/30\n",
      "931/931 [==============================] - 8s 9ms/step - loss: 0.2002 - SA: 0.0952 - val_loss: 0.4073 - val_SA: 0.0977\n",
      "Epoch 21/30\n",
      "931/931 [==============================] - 8s 9ms/step - loss: 0.1856 - SA: 0.0968 - val_loss: 0.4030 - val_SA: 0.1012\n",
      "Epoch 22/30\n",
      "931/931 [==============================] - 9s 9ms/step - loss: 0.1728 - SA: 0.0997 - val_loss: 0.3656 - val_SA: 0.1069\n",
      "Epoch 23/30\n",
      "931/931 [==============================] - 9s 9ms/step - loss: 0.1626 - SA: 0.1039 - val_loss: 0.3498 - val_SA: 0.1070\n",
      "Epoch 24/30\n",
      "931/931 [==============================] - 9s 10ms/step - loss: 0.1531 - SA: 0.1064 - val_loss: 0.3314 - val_SA: 0.1113\n",
      "Epoch 25/30\n",
      "931/931 [==============================] - 9s 10ms/step - loss: 0.1444 - SA: 0.1117 - val_loss: 0.3229 - val_SA: 0.1114\n",
      "Epoch 26/30\n",
      "931/931 [==============================] - 8s 9ms/step - loss: 0.1347 - SA: 0.1153 - val_loss: 0.2985 - val_SA: 0.1171\n",
      "Epoch 27/30\n",
      "931/931 [==============================] - 9s 9ms/step - loss: 0.1256 - SA: 0.1156 - val_loss: 0.2626 - val_SA: 0.1280\n",
      "Epoch 28/30\n",
      "931/931 [==============================] - 9s 10ms/step - loss: 0.1198 - SA: 0.1216 - val_loss: 0.2496 - val_SA: 0.1297\n",
      "Epoch 29/30\n",
      "931/931 [==============================] - 9s 9ms/step - loss: 0.1140 - SA: 0.1258 - val_loss: 0.2455 - val_SA: 0.1319\n",
      "Epoch 30/30\n",
      "931/931 [==============================] - 9s 9ms/step - loss: 0.1080 - SA: 0.1282 - val_loss: 0.2371 - val_SA: 0.1370\n",
      "Cross-validation: experiment_9 on fold 1\n",
      "Epoch 1/30\n",
      "931/931 [==============================] - 11s 10ms/step - loss: 0.5831 - SA: 0.0571 - val_loss: 0.2635 - val_SA: 0.0763 - lr: 1.0000e-05\n",
      "Epoch 2/30\n",
      "931/931 [==============================] - 9s 9ms/step - loss: 0.3105 - SA: 0.0759 - val_loss: 0.1792 - val_SA: 0.0998 - lr: 1.0000e-05\n",
      "Epoch 3/30\n",
      "931/931 [==============================] - 8s 9ms/step - loss: 0.1973 - SA: 0.1000 - val_loss: 0.1065 - val_SA: 0.1369 - lr: 1.0000e-05\n",
      "Epoch 4/30\n",
      "931/931 [==============================] - 9s 9ms/step - loss: 0.1318 - SA: 0.1198 - val_loss: 0.0842 - val_SA: 0.1614 - lr: 1.0000e-05\n",
      "Epoch 5/30\n",
      "931/931 [==============================] - 10s 10ms/step - loss: 0.0930 - SA: 0.1422 - val_loss: 0.0725 - val_SA: 0.1913 - lr: 1.0000e-05\n",
      "Epoch 6/30\n",
      "931/931 [==============================] - 10s 10ms/step - loss: 0.0718 - SA: 0.1673 - val_loss: 0.0674 - val_SA: 0.2144 - lr: 1.0000e-05\n",
      "Epoch 7/30\n",
      "931/931 [==============================] - 10s 10ms/step - loss: 0.0568 - SA: 0.1947 - val_loss: 0.0664 - val_SA: 0.2323 - lr: 1.0000e-05\n",
      "Epoch 8/30\n",
      "931/931 [==============================] - 10s 11ms/step - loss: 0.0474 - SA: 0.2213 - val_loss: 0.0643 - val_SA: 0.2405 - lr: 1.0000e-05\n",
      "Epoch 9/30\n",
      "931/931 [==============================] - 9s 10ms/step - loss: 0.0411 - SA: 0.2469 - val_loss: 0.0612 - val_SA: 0.2566 - lr: 1.0000e-05\n",
      "Epoch 10/30\n",
      "931/931 [==============================] - 9s 10ms/step - loss: 0.0361 - SA: 0.2725 - val_loss: 0.0596 - val_SA: 0.2618 - lr: 1.0000e-05\n",
      "Epoch 11/30\n",
      "931/931 [==============================] - 10s 11ms/step - loss: 0.0326 - SA: 0.2935 - val_loss: 0.0580 - val_SA: 0.2733 - lr: 1.0000e-05\n",
      "Epoch 12/30\n",
      "931/931 [==============================] - 10s 11ms/step - loss: 0.0298 - SA: 0.3108 - val_loss: 0.0565 - val_SA: 0.2790 - lr: 1.0000e-05\n",
      "Epoch 13/30\n",
      "931/931 [==============================] - 11s 11ms/step - loss: 0.0270 - SA: 0.3263 - val_loss: 0.0558 - val_SA: 0.2731 - lr: 1.0000e-05\n",
      "Epoch 14/30\n",
      "931/931 [==============================] - 11s 12ms/step - loss: 0.0250 - SA: 0.3437 - val_loss: 0.0538 - val_SA: 0.2745 - lr: 1.0000e-05\n",
      "Epoch 15/30\n",
      "931/931 [==============================] - 12s 12ms/step - loss: 0.0246 - SA: 0.3532 - val_loss: 0.0528 - val_SA: 0.2814 - lr: 1.0000e-06\n",
      "Epoch 16/30\n",
      "931/931 [==============================] - 11s 11ms/step - loss: 0.0240 - SA: 0.3592 - val_loss: 0.0519 - val_SA: 0.2746 - lr: 1.0000e-06\n",
      "Epoch 17/30\n",
      "931/931 [==============================] - 10s 11ms/step - loss: 0.0236 - SA: 0.3570 - val_loss: 0.0520 - val_SA: 0.2849 - lr: 1.0000e-06\n",
      "Epoch 18/30\n",
      "931/931 [==============================] - 10s 11ms/step - loss: 0.0234 - SA: 0.3590 - val_loss: 0.0515 - val_SA: 0.2842 - lr: 1.0000e-06\n",
      "Epoch 19/30\n",
      "931/931 [==============================] - 10s 10ms/step - loss: 0.0230 - SA: 0.3601 - val_loss: 0.0519 - val_SA: 0.2790 - lr: 1.0000e-06\n",
      "Epoch 20/30\n",
      "931/931 [==============================] - 10s 11ms/step - loss: 0.0230 - SA: 0.3617 - val_loss: 0.0517 - val_SA: 0.2887 - lr: 1.0000e-06\n",
      "Cross-validation: experiment_9 on fold 2\n",
      "Epoch 1/30\n",
      "931/931 [==============================] - 13s 11ms/step - loss: 0.5994 - SA: 0.0571 - val_loss: 0.2831 - val_SA: 0.0699 - lr: 1.0000e-05\n",
      "Epoch 2/30\n",
      "931/931 [==============================] - 10s 11ms/step - loss: 0.3074 - SA: 0.0797 - val_loss: 0.2230 - val_SA: 0.0763 - lr: 1.0000e-05\n",
      "Epoch 3/30\n",
      "931/931 [==============================] - 10s 11ms/step - loss: 0.1910 - SA: 0.0967 - val_loss: 0.1301 - val_SA: 0.1105 - lr: 1.0000e-05\n",
      "Epoch 4/30\n",
      "931/931 [==============================] - 10s 10ms/step - loss: 0.1292 - SA: 0.1175 - val_loss: 0.0837 - val_SA: 0.1516 - lr: 1.0000e-05\n",
      "Epoch 5/30\n",
      "931/931 [==============================] - 10s 11ms/step - loss: 0.0917 - SA: 0.1456 - val_loss: 0.0611 - val_SA: 0.2223 - lr: 1.0000e-05\n",
      "Epoch 6/30\n",
      "931/931 [==============================] - 11s 12ms/step - loss: 0.0702 - SA: 0.1687 - val_loss: 0.0542 - val_SA: 0.2554 - lr: 1.0000e-05\n",
      "Epoch 7/30\n",
      "927/931 [============================>.] - ETA: 0s - loss: 0.0570 - SA: 0.1930"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[36], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m experiment_name, experiment_params \u001B[38;5;129;01min\u001B[39;00m experiments\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m----> 2\u001B[0m     \u001B[43mrun_cross_validation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexperiment_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexperiment_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m40\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[35], line 42\u001B[0m, in \u001B[0;36mrun_cross_validation\u001B[0;34m(experiment_name, experiment_params, batch_size)\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCross-validation: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mexperiment_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m on fold \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     40\u001B[0m tensorboard_callback\u001B[38;5;241m.\u001B[39mlog_dir \u001B[38;5;241m=\u001B[39m log_dir \u001B[38;5;241m+\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mexperiment_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/fold_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 42\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     43\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdrop_remainder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprefetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mAUTOTUNE\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     44\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_dataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdrop_remainder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprefetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mAUTOTUNE\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     45\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks_list\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     46\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m30\u001B[39;49m\n\u001B[1;32m     47\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/av_training/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/anaconda3/envs/av_training/lib/python3.10/site-packages/keras/src/engine/training.py:1856\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1840\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_eval_data_handler\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1841\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_eval_data_handler \u001B[38;5;241m=\u001B[39m data_adapter\u001B[38;5;241m.\u001B[39mget_data_handler(\n\u001B[1;32m   1842\u001B[0m         x\u001B[38;5;241m=\u001B[39mval_x,\n\u001B[1;32m   1843\u001B[0m         y\u001B[38;5;241m=\u001B[39mval_y,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1854\u001B[0m         pss_evaluation_shards\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pss_evaluation_shards,\n\u001B[1;32m   1855\u001B[0m     )\n\u001B[0;32m-> 1856\u001B[0m val_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1857\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_x\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1858\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_y\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1859\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_sample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1860\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_batch_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1861\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1862\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1863\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_queue_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_queue_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1864\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mworkers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1865\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_multiprocessing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1866\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1867\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_use_cached_eval_dataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1868\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1869\u001B[0m val_logs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m   1870\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mval_\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m name: val \u001B[38;5;28;01mfor\u001B[39;00m name, val \u001B[38;5;129;01min\u001B[39;00m val_logs\u001B[38;5;241m.\u001B[39mitems()\n\u001B[1;32m   1871\u001B[0m }\n\u001B[1;32m   1872\u001B[0m epoch_logs\u001B[38;5;241m.\u001B[39mupdate(val_logs)\n",
      "File \u001B[0;32m~/anaconda3/envs/av_training/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/anaconda3/envs/av_training/lib/python3.10/site-packages/keras/src/engine/training.py:2296\u001B[0m, in \u001B[0;36mModel.evaluate\u001B[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001B[0m\n\u001B[1;32m   2292\u001B[0m             \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   2293\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m\"\u001B[39m, step_num\u001B[38;5;241m=\u001B[39mstep, _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   2294\u001B[0m             ):\n\u001B[1;32m   2295\u001B[0m                 callbacks\u001B[38;5;241m.\u001B[39mon_test_batch_begin(step)\n\u001B[0;32m-> 2296\u001B[0m                 logs \u001B[38;5;241m=\u001B[39m \u001B[43mtest_function_runner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_step\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2297\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mdataset_or_iterator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2298\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mdata_handler\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2299\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2300\u001B[0m \u001B[43m                    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_pss_evaluation_shards\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2301\u001B[0m \u001B[43m                \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2303\u001B[0m logs \u001B[38;5;241m=\u001B[39m tf_utils\u001B[38;5;241m.\u001B[39msync_to_numpy_or_python_type(logs)\n\u001B[1;32m   2304\u001B[0m \u001B[38;5;66;03m# Override with model metrics instead of last step logs\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/av_training/lib/python3.10/site-packages/keras/src/engine/training.py:4108\u001B[0m, in \u001B[0;36m_TestFunction.run_step\u001B[0;34m(self, dataset_or_iterator, data_handler, step, unused_shards)\u001B[0m\n\u001B[1;32m   4107\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun_step\u001B[39m(\u001B[38;5;28mself\u001B[39m, dataset_or_iterator, data_handler, step, unused_shards):\n\u001B[0;32m-> 4108\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset_or_iterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4109\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   4110\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/anaconda3/envs/av_training/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/anaconda3/envs/av_training/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    829\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    831\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 832\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    834\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    835\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/anaconda3/envs/av_training/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:877\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    874\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    875\u001B[0m \u001B[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001B[39;00m\n\u001B[1;32m    876\u001B[0m \u001B[38;5;66;03m# run the first trace but we should fail if variables are created.\u001B[39;00m\n\u001B[0;32m--> 877\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    878\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_variable_creation_config\u001B[49m\n\u001B[1;32m    879\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    880\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_created_variables:\n\u001B[1;32m    881\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCreating variables on a non-first call to a function\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    882\u001B[0m                    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m decorated with tf.function.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/av_training/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:138\u001B[0m, in \u001B[0;36mcall_function\u001B[0;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[1;32m    136\u001B[0m \u001B[38;5;66;03m# Bind it ourselves to skip unnecessary canonicalization of default call.\u001B[39;00m\n\u001B[1;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m \u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munpack_inputs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbound_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m function\u001B[38;5;241m.\u001B[39m_call_flat(  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m    140\u001B[0m     flat_inputs, captured_inputs\u001B[38;5;241m=\u001B[39mfunction\u001B[38;5;241m.\u001B[39mcaptured_inputs\n\u001B[1;32m    141\u001B[0m )\n",
      "File \u001B[0;32m~/anaconda3/envs/av_training/lib/python3.10/site-packages/tensorflow/core/function/polymorphism/function_type.py:391\u001B[0m, in \u001B[0;36mFunctionType.unpack_inputs\u001B[0;34m(self, bound_parameters)\u001B[0m\n\u001B[1;32m    388\u001B[0m flat \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    389\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m sorted_parameters:\n\u001B[1;32m    390\u001B[0m   flat\u001B[38;5;241m.\u001B[39mextend(\n\u001B[0;32m--> 391\u001B[0m       \u001B[43mp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtype_constraint\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_tensors\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbound_parameters\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marguments\u001B[49m\u001B[43m[\u001B[49m\u001B[43mp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    392\u001B[0m   )\n\u001B[1;32m    394\u001B[0m dealiased_inputs \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    395\u001B[0m ids_used \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/anaconda3/envs/av_training/lib/python3.10/site-packages/tensorflow/python/framework/type_spec.py:252\u001B[0m, in \u001B[0;36mTypeSpec.to_tensors\u001B[0;34m(self, value)\u001B[0m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"See TraceType base class for details. Do not override.\"\"\"\u001B[39;00m\n\u001B[1;32m    251\u001B[0m tensors \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m--> 252\u001B[0m \u001B[43mnest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_structure\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mspec\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtensors\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mextend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mspec\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_tensors\u001B[49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_component_specs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_to_components\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    256\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m tensors\n",
      "File \u001B[0;32m~/anaconda3/envs/av_training/lib/python3.10/site-packages/tensorflow/python/util/nest.py:631\u001B[0m, in \u001B[0;36mmap_structure\u001B[0;34m(func, *structure, **kwargs)\u001B[0m\n\u001B[1;32m    545\u001B[0m \u001B[38;5;129m@tf_export\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnest.map_structure\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    546\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmap_structure\u001B[39m(func, \u001B[38;5;241m*\u001B[39mstructure, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    547\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001B[39;00m\n\u001B[1;32m    548\u001B[0m \n\u001B[1;32m    549\u001B[0m \u001B[38;5;124;03m  Refer to [tf.nest](https://www.tensorflow.org/api_docs/python/tf/nest)\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    629\u001B[0m \u001B[38;5;124;03m    ValueError: If wrong keyword arguments are provided.\u001B[39;00m\n\u001B[1;32m    630\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m--> 631\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mnest_util\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_structure\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    632\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnest_util\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mModality\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCORE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mstructure\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    633\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/av_training/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:1066\u001B[0m, in \u001B[0;36mmap_structure\u001B[0;34m(modality, func, *structure, **kwargs)\u001B[0m\n\u001B[1;32m    969\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001B[39;00m\n\u001B[1;32m    970\u001B[0m \n\u001B[1;32m    971\u001B[0m \u001B[38;5;124;03m- For Modality.CORE: Refer to\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1063\u001B[0m \u001B[38;5;124;03m  ValueError: If wrong keyword arguments are provided.\u001B[39;00m\n\u001B[1;32m   1064\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1065\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m modality \u001B[38;5;241m==\u001B[39m Modality\u001B[38;5;241m.\u001B[39mCORE:\n\u001B[0;32m-> 1066\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_tf_core_map_structure\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mstructure\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1067\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m modality \u001B[38;5;241m==\u001B[39m Modality\u001B[38;5;241m.\u001B[39mDATA:\n\u001B[1;32m   1068\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m _tf_data_map_structure(func, \u001B[38;5;241m*\u001B[39mstructure, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/envs/av_training/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:1094\u001B[0m, in \u001B[0;36m_tf_core_map_structure\u001B[0;34m(func, *structure, **kwargs)\u001B[0m\n\u001B[1;32m   1087\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1088\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOnly valid keyword arguments are `check_types` and \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1089\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`expand_composites`, not: `\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m`\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1090\u001B[0m       \u001B[38;5;241m%\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`, `\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(kwargs\u001B[38;5;241m.\u001B[39mkeys())\n\u001B[1;32m   1091\u001B[0m   )\n\u001B[1;32m   1093\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m other \u001B[38;5;129;01min\u001B[39;00m structure[\u001B[38;5;241m1\u001B[39m:]:\n\u001B[0;32m-> 1094\u001B[0m   \u001B[43m_tf_core_assert_same_structure\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1095\u001B[0m \u001B[43m      \u001B[49m\u001B[43mstructure\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1096\u001B[0m \u001B[43m      \u001B[49m\u001B[43mother\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1097\u001B[0m \u001B[43m      \u001B[49m\u001B[43mcheck_types\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcheck_types\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1098\u001B[0m \u001B[43m      \u001B[49m\u001B[43mexpand_composites\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexpand_composites\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1099\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1101\u001B[0m flat_structure \u001B[38;5;241m=\u001B[39m (_tf_core_flatten(s, expand_composites) \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m structure)\n\u001B[1;32m   1102\u001B[0m entries \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mflat_structure)\n",
      "File \u001B[0;32m~/anaconda3/envs/av_training/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:530\u001B[0m, in \u001B[0;36m_tf_core_assert_same_structure\u001B[0;34m(nest1, nest2, check_types, expand_composites)\u001B[0m\n\u001B[1;32m    528\u001B[0m expand_composites \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mbool\u001B[39m(expand_composites)\n\u001B[1;32m    529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 530\u001B[0m   \u001B[43m_pywrap_utils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mAssertSameStructure\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    531\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnest1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnest2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheck_types\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexpand_composites\u001B[49m\n\u001B[1;32m    532\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    533\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mValueError\u001B[39;00m, \u001B[38;5;167;01mTypeError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    534\u001B[0m   str1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(_tf_core_map_structure(\u001B[38;5;28;01mlambda\u001B[39;00m _: _DOT, nest1))\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# def scheduler(epoch, lr):\n",
    "#     if epoch in (4, 10, 15):\n",
    "#         return lr * 0.5\n",
    "#     else:\n",
    "#         return lr\n",
    "# \n",
    "# callback_lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ],
   "id": "laI7Ltmlo_rh",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c593055070c2cb7b",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "aborted",
     "timestamp": 1712395168528,
     "user": {
      "displayName": "Jesus Armando Anaya",
      "userId": "10837992074590593370"
     },
     "user_tz": 420
    },
    "id": "c593055070c2cb7b"
   },
   "source": [
    "# %load_ext tensorboard"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "tiC8X2OCeucW",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "aborted",
     "timestamp": 1712395168528,
     "user": {
      "displayName": "Jesus Armando Anaya",
      "userId": "10837992074590593370"
     },
     "user_tz": 420
    },
    "id": "tiC8X2OCeucW"
   },
   "source": [
    "# %tensorboard --logdir ./logs/fit/"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
