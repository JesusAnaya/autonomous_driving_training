{
 "cells": [
  {
   "cell_type": "code",
   "id": "016b93d2-c0ae-4f9c-bfd6-4bf302a27c0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T22:08:21.839740Z",
     "start_time": "2024-04-05T22:08:21.836598Z"
    }
   },
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "8a0a6718-a28b-42ca-9656-884c3a31460a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T22:08:23.613645Z",
     "start_time": "2024-04-05T22:08:21.848352Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import IPython.display as display\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from PIL import Image, ImageDraw\n",
    "from datetime import datetime"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "7f23393c-24d3-4bc4-a0db-f18b200765a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T22:08:23.787598Z",
     "start_time": "2024-04-05T22:08:23.614853Z"
    }
   },
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"TensorFlow version: \", tf.__version__)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "TensorFlow version:  2.14.0\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "91112d1d-bc33-494c-abe6-be815995e836",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T22:08:23.812971Z",
     "start_time": "2024-04-05T22:08:23.788616Z"
    }
   },
   "source": [
    "def parse_tfrecord_fn(example_proto):\n",
    "    # Define the feature description for parsing\n",
    "    feature_description = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'steering': tf.io.FixedLenFeature([], tf.float32),\n",
    "    }\n",
    "    \n",
    "    parsed_features = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    image = tf.image.decode_jpeg(parsed_features['image'], channels=3)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.image.rgb_to_yuv(image)\n",
    "    image = (image / 127.5) - 1.0\n",
    "    \n",
    "    return image, parsed_features['steering']\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "4a83ec71-287b-43e9-ba84-9c0aa19957fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T22:08:23.837865Z",
     "start_time": "2024-04-05T22:08:23.813965Z"
    }
   },
   "source": [
    "def load_dataset(tfrecord_files):\n",
    "    raw_dataset = tf.data.TFRecordDataset(tfrecord_files)\n",
    "    parsed_dataset = raw_dataset.map(parse_tfrecord_fn)\n",
    "    return parsed_dataset"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T22:08:24.500573Z",
     "start_time": "2024-04-05T22:08:23.838770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a sequential model\n",
    "model = tf.keras.Sequential([\n",
    "    # First convolutional layer, input shape specified\n",
    "    layers.InputLayer((66, 200, 3)),\n",
    "    layers.Conv2D(24, kernel_size=5, strides=2, padding='valid'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "\n",
    "    # Second convolutional layer\n",
    "    layers.Conv2D(36, kernel_size=5, strides=2, padding='valid'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "\n",
    "    # Third convolutional layer\n",
    "    layers.Conv2D(48, kernel_size=5, strides=2, padding='valid'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "\n",
    "    # Fourth convolutional layer\n",
    "    layers.Conv2D(64, kernel_size=3, strides=1, padding='valid'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "\n",
    "    # Fifth convolutional layer\n",
    "    layers.Conv2D(64, kernel_size=3, strides=1, padding='valid'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "\n",
    "    # Flatten the output to feed into the dense layers\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.5),\n",
    "\n",
    "    # First fully connected layer\n",
    "    layers.Dense(1164),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "\n",
    "    # Second fully connected layer\n",
    "    layers.Dense(100),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "\n",
    "    # Third fully connected layer\n",
    "    layers.Dense(50),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "\n",
    "    # Fourth fully connected layer\n",
    "    layers.Dense(10),\n",
    "    layers.ReLU(),\n",
    "\n",
    "    # Output layer\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Summary of the model to see the structure and parameters\n",
    "model.summary()\n"
   ],
   "id": "3cbe7e62-b5f9-4b16-96da-c3dca6e906bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 31, 98, 24)        1824      \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 31, 98, 24)        96        \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 31, 98, 24)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 47, 36)        21636     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 14, 47, 36)        144       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 14, 47, 36)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 5, 22, 48)         43248     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 5, 22, 48)         192       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 5, 22, 48)         0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 3, 20, 64)         27712     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 3, 20, 64)         256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_3 (ReLU)              (None, 3, 20, 64)         0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 1, 18, 64)         36928     \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 1, 18, 64)         256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_4 (ReLU)              (None, 1, 18, 64)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1152)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1152)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1164)              1342092   \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 1164)              4656      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_5 (ReLU)              (None, 1164)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               116500    \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 100)               400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_6 (ReLU)              (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 50)                200       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_7 (ReLU)              (None, 50)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                510       \n",
      "                                                                 \n",
      " re_lu_8 (ReLU)              (None, 10)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1601711 (6.11 MB)\n",
      "Trainable params: 1598611 (6.10 MB)\n",
      "Non-trainable params: 3100 (12.11 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T22:08:33.851081Z",
     "start_time": "2024-04-05T22:08:24.501139Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tfrecord_files = list(glob.glob(\"/home/anaya/Develop/autonomous_driving_training/datasets/*.tfrecord\"))\n",
    "parsed_dataset = load_dataset(tfrecord_files)\n",
    "shuffled_dataset = parsed_dataset.shuffle(2040)\n",
    "\n",
    "# Determine split sizes\n",
    "total_items = sum([1 for _ in shuffled_dataset.as_numpy_iterator()])\n",
    "train_size = int(0.6 * total_items)\n",
    "val_size = int(0.2 * total_items)\n",
    "test_size = total_items - train_size - val_size\n"
   ],
   "id": "0cb9d87c-a872-4e94-87e4-140025763167",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T22:08:33.855013Z",
     "start_time": "2024-04-05T22:08:33.852165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Total items: \", total_items)\n",
    "print(\"Train size: \", train_size)\n",
    "print(\"Validation size: \", val_size)\n",
    "print(\"Test size: \", test_size)"
   ],
   "id": "3494288b50d41039",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total items:  123138\n",
      "Train size:  73882\n",
      "Validation size:  24627\n",
      "Test size:  24629\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T22:08:33.892552Z",
     "start_time": "2024-04-05T22:08:33.855794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split the dataset\n",
    "train_dataset = shuffled_dataset.take(train_size)\n",
    "test_val_dataset = shuffled_dataset.skip(train_size)\n",
    "val_dataset = test_val_dataset.take(val_size)\n",
    "test_dataset = test_val_dataset.skip(val_size)"
   ],
   "id": "1ac24967b8507931",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T22:08:33.924678Z",
     "start_time": "2024-04-05T22:08:33.893560Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Apply any additional preprocessing here (e.g., batching)\n",
    "train_dataset = train_dataset.batch(64, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.batch(64, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(64, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n"
   ],
   "id": "3bdfe79ca61d555b",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# for data_row in train_dataset.take(1):\n",
    "#     print(data_row[1][0])\n",
    "#     image = Image.fromarray(((data_row[0][0].numpy() + 1.0) * 127.5).astype(np.uint8))\n",
    "#     display.display(image)\n",
    "    "
   ],
   "id": "628201848a99a393",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d329c0fe-422c-48bf-b53f-516f090ac718",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T22:08:34.036810Z",
     "start_time": "2024-04-05T22:08:34.029268Z"
    }
   },
   "source": [
    "# Compile the model (make sure to specify the loss and optimizer)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4, weight_decay=1e-5),\n",
    "    loss=tf.keras.losses.MeanSquaredError()\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T22:08:34.057202Z",
     "start_time": "2024-04-05T22:08:34.037583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "log_dir = \"../logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ],
   "id": "80ec2e72993dc7fb",
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "beab0867-4046-4505-a3c3-a70468e1a10b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T22:12:24.173184Z",
     "start_time": "2024-04-05T22:08:34.057836Z"
    }
   },
   "source": [
    "# Step 5: Train the Model\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        epochs=20,\n",
    "        validation_data=val_dataset,\n",
    "        callbacks=[tensorboard_callback]\n",
    "    )"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1154/1154 [==============================] - 15s 10ms/step - loss: 0.0347 - val_loss: 0.0139\n",
      "Epoch 2/20\n",
      "1154/1154 [==============================] - 11s 9ms/step - loss: 0.0122 - val_loss: 0.0107\n",
      "Epoch 3/20\n",
      "1154/1154 [==============================] - 11s 9ms/step - loss: 0.0107 - val_loss: 0.0093\n",
      "Epoch 4/20\n",
      "1154/1154 [==============================] - 11s 9ms/step - loss: 0.0094 - val_loss: 0.0098\n",
      "Epoch 5/20\n",
      "1154/1154 [==============================] - 11s 10ms/step - loss: 0.0084 - val_loss: 0.0080\n",
      "Epoch 6/20\n",
      "1154/1154 [==============================] - 11s 10ms/step - loss: 0.0075 - val_loss: 0.0076\n",
      "Epoch 7/20\n",
      "1154/1154 [==============================] - 11s 10ms/step - loss: 0.0068 - val_loss: 0.0072\n",
      "Epoch 8/20\n",
      "1154/1154 [==============================] - 11s 10ms/step - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 9/20\n",
      "1154/1154 [==============================] - 11s 10ms/step - loss: 0.0054 - val_loss: 0.0077\n",
      "Epoch 10/20\n",
      "1154/1154 [==============================] - 11s 10ms/step - loss: 0.0051 - val_loss: 0.0073\n",
      "Epoch 11/20\n",
      "1154/1154 [==============================] - 11s 10ms/step - loss: 0.0046 - val_loss: 0.0070\n",
      "Epoch 12/20\n",
      "1154/1154 [==============================] - 12s 10ms/step - loss: 0.0043 - val_loss: 0.0071\n",
      "Epoch 13/20\n",
      "1154/1154 [==============================] - 11s 10ms/step - loss: 0.0040 - val_loss: 0.0065\n",
      "Epoch 14/20\n",
      "1154/1154 [==============================] - 12s 10ms/step - loss: 0.0038 - val_loss: 0.0077\n",
      "Epoch 15/20\n",
      "1154/1154 [==============================] - 12s 10ms/step - loss: 0.0035 - val_loss: 0.0073\n",
      "Epoch 16/20\n",
      "1154/1154 [==============================] - 11s 10ms/step - loss: 0.0033 - val_loss: 0.0073\n",
      "Epoch 17/20\n",
      "1154/1154 [==============================] - 12s 10ms/step - loss: 0.0031 - val_loss: 0.0067\n",
      "Epoch 18/20\n",
      "1154/1154 [==============================] - 12s 10ms/step - loss: 0.0029 - val_loss: 0.0073\n",
      "Epoch 19/20\n",
      "1154/1154 [==============================] - 11s 10ms/step - loss: 0.0027 - val_loss: 0.0097\n",
      "Epoch 20/20\n",
      "1154/1154 [==============================] - 11s 10ms/step - loss: 0.0026 - val_loss: 0.0069\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T22:12:26.797341Z",
     "start_time": "2024-04-05T22:12:24.174149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 6: Evaluate the Model\n",
    "model.evaluate(test_dataset)"
   ],
   "id": "675586e3f9facbe4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384/384 [==============================] - 3s 3ms/step - loss: 0.0103\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.010286141186952591"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T22:12:26.802294Z",
     "start_time": "2024-04-05T22:12:26.799450Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "c593055070c2cb7b",
   "outputs": [],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
